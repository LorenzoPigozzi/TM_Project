{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Project\n",
    "\n",
    "### NOVA IMS MT Metrics Shared Task\n",
    "\n",
    "**Group members:**\n",
    "- Lorenzo Pigozzi\t--- m20200745\n",
    "- Davide Farinati\n",
    "- Antonio\n",
    "- Luis Reis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries and corpora <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# word's preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# chinese library\n",
    "import jieba\n",
    "\n",
    "# LaBSE model\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "# from transformers import BertModel, BertTokenizerFast\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing the corpora\n",
    "# cs_en = pd.read_csv('corpus\\cs-en\\scores.csv')\n",
    "# de_en = pd.read_csv('corpus\\de-en\\scores.csv')\n",
    "# ru_en = pd.read_csv('corpus\\scores_ru-en.csv')\n",
    "# zh_en = pd.read_csv('corpus\\zh-en\\scores.csv')\n",
    "en_fi = pd.read_csv('corpus\\en-fi\\scores.csv')\n",
    "# en_zh = pd.read_csv('corpus\\en-zh\\scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can turn yourself into a pineapple, a dog ...</td>\n",
       "      <td>Voit muuttaa itsesi ananasta, koirasta tai Roy...</td>\n",
       "      <td>Voit muuttaa itsesi ananakseksi, koiraksi tai ...</td>\n",
       "      <td>-0.286195</td>\n",
       "      <td>34.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Also shot were three men: two 29-year-olds and...</td>\n",
       "      <td>Myös ammuttiin kolme miestä: kaksi 29-vuotiait...</td>\n",
       "      <td>Myös kolmea miestä ammuttiin: kahta 29-vuotias...</td>\n",
       "      <td>0.547076</td>\n",
       "      <td>58.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The information is stored at the cash register...</td>\n",
       "      <td>Tiedot tallennetaan kassakoneisiin joka tapauk...</td>\n",
       "      <td>Tiedot kuitenkin tallentuvat kassoilla joka ta...</td>\n",
       "      <td>1.122476</td>\n",
       "      <td>74.60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xinhua says that there were traces of hydrochl...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin näytteestä oli sunn...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin sunnuntaina antamas...</td>\n",
       "      <td>0.383095</td>\n",
       "      <td>53.60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacDonald, who was brought on board CBC's comm...</td>\n",
       "      <td>Voitaisiin kuulla CBD: n kommenttitiimin toimi...</td>\n",
       "      <td>MacDonaldin, joka tuli CBC:n selostajatiimiin ...</td>\n",
       "      <td>-0.493065</td>\n",
       "      <td>32.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  You can turn yourself into a pineapple, a dog ...   \n",
       "1  Also shot were three men: two 29-year-olds and...   \n",
       "2  The information is stored at the cash register...   \n",
       "3  Xinhua says that there were traces of hydrochl...   \n",
       "4  MacDonald, who was brought on board CBC's comm...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Voit muuttaa itsesi ananasta, koirasta tai Roy...   \n",
       "1  Myös ammuttiin kolme miestä: kaksi 29-vuotiait...   \n",
       "2  Tiedot tallennetaan kassakoneisiin joka tapauk...   \n",
       "3  Xinhua kertoo, että Xinyin näytteestä oli sunn...   \n",
       "4  Voitaisiin kuulla CBD: n kommenttitiimin toimi...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Voit muuttaa itsesi ananakseksi, koiraksi tai ... -0.286195      34.20   \n",
       "1  Myös kolmea miestä ammuttiin: kahta 29-vuotias...  0.547076      58.40   \n",
       "2  Tiedot kuitenkin tallentuvat kassoilla joka ta...  1.122476      74.60   \n",
       "3  Xinhua kertoo, että Xinyin sunnuntaina antamas...  0.383095      53.60   \n",
       "4  MacDonaldin, joka tuli CBC:n selostajatiimiin ... -0.493065      32.25   \n",
       "\n",
       "   annotators  \n",
       "0           5  \n",
       "1           5  \n",
       "2           5  \n",
       "3           5  \n",
       "4           4  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = en_fi.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. Pre-processing <a class=\"anchor\" id=\"3.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the necessary variables for the baseline\n",
    "source_reference = corpus[['source','reference']]\n",
    "source_translation = corpus[['source','translation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can turn yourself into a pineapple, a dog ...</td>\n",
       "      <td>Voit muuttaa itsesi ananasta, koirasta tai Roy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Also shot were three men: two 29-year-olds and...</td>\n",
       "      <td>Myös ammuttiin kolme miestä: kaksi 29-vuotiait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The information is stored at the cash register...</td>\n",
       "      <td>Tiedot tallennetaan kassakoneisiin joka tapauk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xinhua says that there were traces of hydrochl...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin näytteestä oli sunn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacDonald, who was brought on board CBC's comm...</td>\n",
       "      <td>Voitaisiin kuulla CBD: n kommenttitiimin toimi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  You can turn yourself into a pineapple, a dog ...   \n",
       "1  Also shot were three men: two 29-year-olds and...   \n",
       "2  The information is stored at the cash register...   \n",
       "3  Xinhua says that there were traces of hydrochl...   \n",
       "4  MacDonald, who was brought on board CBC's comm...   \n",
       "\n",
       "                                           reference  \n",
       "0  Voit muuttaa itsesi ananasta, koirasta tai Roy...  \n",
       "1  Myös ammuttiin kolme miestä: kaksi 29-vuotiait...  \n",
       "2  Tiedot tallennetaan kassakoneisiin joka tapauk...  \n",
       "3  Xinhua kertoo, että Xinyin näytteestä oli sunn...  \n",
       "4  Voitaisiin kuulla CBD: n kommenttitiimin toimi...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_reference.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Cleaning <a class=\"anchor\" id=\"3.1.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text_list,\n",
    "          lower = False,\n",
    "          keep_numbers = False,\n",
    "          keep_expression = False,\n",
    "          remove_char = False,\n",
    "          remove_stop = False,\n",
    "          remove_tag = False,\n",
    "          lemmatize = False,\n",
    "          stemmer = False,\n",
    "          english = True\n",
    "          ):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    if english:\n",
    "        lang = 'english'\n",
    "    else:\n",
    "        lang = 'finnish'\n",
    "    \n",
    "    stop = set(stopwords.words(lang))\n",
    "    stem = SnowballStemmer(lang)\n",
    "    \n",
    "    updates = []\n",
    "    for j in range(len(text_list)):\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        if lower:\n",
    "            text = text.lower()\n",
    "            \n",
    "        #KEEP NUMBERS AS TOKENS\n",
    "        if not keep_numbers:\n",
    "            text = re.sub(\"[\\d+]\", 'X', text)\n",
    "        \n",
    "        #KEEP '?' and '!' AS TOKENS\n",
    "        if not keep_expression:\n",
    "            text = re.sub(\"[\\?|\\!]\", 'EXPRESSION', text)\n",
    "            \n",
    "        #REMOVE TAGS\n",
    "        if remove_tag:\n",
    "            text = BeautifulSoup(text).get_text()\n",
    "            \n",
    "        #REMOVE THAT IS NOT TEXT\n",
    "        if remove_char:\n",
    "            text = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "        \n",
    "        #REMOVE STOP WORDS\n",
    "        if remove_stop:\n",
    "            text = ' '.join([word for word in text.split(' ') if word not in stop])\n",
    "        \n",
    "        #LEMMATIZATION\n",
    "        if lemmatize:\n",
    "            if english:\n",
    "                lemma = WordNetLemmatizer()\n",
    "                text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "        \n",
    "        #STEMMER\n",
    "        if stemmer:\n",
    "            text = \" \".join(stem.stem(word) for word in text.split())\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def clean_ch(text_list, keep_numbers=False, remove_punctuation=False, remove_stop = False, stopwords_set='merged'):\n",
    "    \"\"\"\n",
    "    Function that removes chinese stopwords\n",
    "    \n",
    "    :param stopwords_set: remove words of both sets (merged), just the 1st (fst) or just the second (snd) \n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    \n",
    "    zh_stopwords1 = [line.strip() for line in open('chinese_stopwords/chinese_stopwords1.txt', 'r', encoding='utf-8').readlines()]\n",
    "    zh_stopwords2 = [line.strip() for line in open('chinese_stopwords/chinese_stopwords2.txt', 'r', encoding='utf-8').readlines()]\n",
    "    \n",
    "    if stopwords_set == 'merged':\n",
    "        stop = list(set(zh_stopwords1 + zh_stopwords2))\n",
    "    elif stopwords_set == 'fst':\n",
    "        stop = zh_stopwords1\n",
    "    elif stopwords_set == 'snd':\n",
    "        stop = zh_stopwords2\n",
    "\n",
    "    for j in range(len(text_list)):\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #KEEP NUMBERS AS TOKENS\n",
    "        if keep_numbers:\n",
    "            text = re.sub(\"[\\d+]\", 'X', text)\n",
    "        \n",
    "        # REMOVE PUNCTUATION\n",
    "        if remove_punctuation:\n",
    "            # https://stackoverflow.com/questions/36640587/how-to-remove-chinese-punctuation-in-python\n",
    "            punc = \"！？｡。＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.\"\n",
    "            text = re.sub(r\"[%s]+\" %punc, \"\", text)\n",
    "        \n",
    "        # REMOVE STOP WORDS\n",
    "        if remove_stop:\n",
    "            pretext = text\n",
    "            text = ' '.join([word for word in jieba.cut(text) if word not in stop])\n",
    "            \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def update_df(dataframe, list_updated):\n",
    "    dataframe.update(pd.DataFrame({\"Text\": list_updated}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can turn yourself into a pineapple, a dog ...</td>\n",
       "      <td>Voit muuttaa itsesi ananasta, koirasta tai Roy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Also shot were three men: two 29-year-olds and...</td>\n",
       "      <td>Myös ammuttiin kolme miestä: kaksi 29-vuotiait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The information is stored at the cash register...</td>\n",
       "      <td>Tiedot tallennetaan kassakoneisiin joka tapauk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xinhua says that there were traces of hydrochl...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin näytteestä oli sunn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacDonald, who was brought on board CBC's comm...</td>\n",
       "      <td>Voitaisiin kuulla CBD: n kommenttitiimin toimi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  You can turn yourself into a pineapple, a dog ...   \n",
       "1  Also shot were three men: two 29-year-olds and...   \n",
       "2  The information is stored at the cash register...   \n",
       "3  Xinhua says that there were traces of hydrochl...   \n",
       "4  MacDonald, who was brought on board CBC's comm...   \n",
       "\n",
       "                                           reference  \n",
       "0  Voit muuttaa itsesi ananasta, koirasta tai Roy...  \n",
       "1  Myös ammuttiin kolme miestä: kaksi 29-vuotiait...  \n",
       "2  Tiedot tallennetaan kassakoneisiin joka tapauk...  \n",
       "3  Xinhua kertoo, että Xinyin näytteestä oli sunn...  \n",
       "4  Voitaisiin kuulla CBD: n kommenttitiimin toimi...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_reference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can turn yourself into a pineapple, a dog ...</td>\n",
       "      <td>Voit muuttaa itsesi ananakseksi, koiraksi tai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Also shot were three men: two 29-year-olds and...</td>\n",
       "      <td>Myös kolmea miestä ammuttiin: kahta 29-vuotias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The information is stored at the cash register...</td>\n",
       "      <td>Tiedot kuitenkin tallentuvat kassoilla joka ta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xinhua says that there were traces of hydrochl...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin sunnuntaina antamas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacDonald, who was brought on board CBC's comm...</td>\n",
       "      <td>MacDonaldin, joka tuli CBC:n selostajatiimiin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  You can turn yourself into a pineapple, a dog ...   \n",
       "1  Also shot were three men: two 29-year-olds and...   \n",
       "2  The information is stored at the cash register...   \n",
       "3  Xinhua says that there were traces of hydrochl...   \n",
       "4  MacDonald, who was brought on board CBC's comm...   \n",
       "\n",
       "                                         translation  \n",
       "0  Voit muuttaa itsesi ananakseksi, koiraksi tai ...  \n",
       "1  Myös kolmea miestä ammuttiin: kahta 29-vuotias...  \n",
       "2  Tiedot kuitenkin tallentuvat kassoilla joka ta...  \n",
       "3  Xinhua kertoo, että Xinyin sunnuntaina antamas...  \n",
       "4  MacDonaldin, joka tuli CBC:n selostajatiimiin ...  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_translation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ENGLISH - CHINESE\n",
    "# source_reference['reference'] = clean_ch(source_reference['reference'], \n",
    "#                                 keep_numbers = False,\n",
    "#                                 remove_punctuation = False,\n",
    "#                                 remove_stop = True,\n",
    "#                                 stopwords_set = 'snd')\n",
    "\n",
    "# source_reference['source'] = clean(source_reference['source'], \n",
    "#                                       lower = True, \n",
    "#                                       remove_char = True,\n",
    "#                                       remove_stop = True,\n",
    "#                                       lemmatize = True,\n",
    "#                                       stemmer = False,\n",
    "#                                       english = True)\n",
    "\n",
    "# # CHINESE - ENGLISH\n",
    "# source_reference['source'] = clean_ch(source_reference['source'], \n",
    "#                                 keep_numbers = False,\n",
    "#                                 remove_punctuation = False,\n",
    "#                                 remove_stop = True,\n",
    "#                                 stopwords_set = 'snd')\n",
    "\n",
    "# source_reference['reference'] = clean(source_reference['reference'], \n",
    "#                                       lower = True, \n",
    "#                                       remove_char = True,\n",
    "#                                       remove_stop = True,\n",
    "#                                       lemmatize = True,\n",
    "#                                       stemmer = False,\n",
    "#                                       english = True)\n",
    "\n",
    "\n",
    "# ENGLISH - FINNISH\n",
    "source_reference['reference'] = clean(source_reference['reference'], \n",
    "                                      lower = True, \n",
    "                                      remove_char = True,\n",
    "                                      remove_stop = True,\n",
    "                                      lemmatize = True,\n",
    "                                      stemmer = False,\n",
    "                                      english = False)\n",
    "\n",
    "source_reference['source'] = clean(source_reference['source'], \n",
    "                                      lower = True, \n",
    "                                      remove_char = True,\n",
    "                                      remove_stop = True,\n",
    "                                      lemmatize = True,\n",
    "                                      stemmer = False,\n",
    "                                      english = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ENGLISH - CHINESE\n",
    "# source_translation['translation'] = clean_ch(source_translation['translation'], \n",
    "#                                 keep_numbers = False,\n",
    "#                                 remove_punctuation = False,\n",
    "#                                 remove_stop = True,\n",
    "#                                 stopwords_set = 'snd')\n",
    "\n",
    "# source_translation['source'] = clean(source_translation['source'], \n",
    "#                                           lower = True, \n",
    "#                                            remove_char = True,\n",
    "#                                            remove_stop = True,\n",
    "#                                             lemmatize = True,\n",
    "#                                             stemmer = False,\n",
    "#                                             english = True)\n",
    "\n",
    "\n",
    "# # CHINESE - ENGLISH\n",
    "# source_translation['source'] = clean_ch(source_translation['source'], \n",
    "#                                 keep_numbers = False,\n",
    "#                                 remove_punctuation = False,\n",
    "#                                 remove_stop = True,\n",
    "#                                 stopwords_set = 'snd')\n",
    "\n",
    "# source_translation['translation'] = clean(source_translation['translation'], \n",
    "#                                           lower = True, \n",
    "#                                            remove_char = True,\n",
    "#                                            remove_stop = True,\n",
    "#                                             lemmatize = True,\n",
    "#                                             stemmer = False,\n",
    "#                                             english = True)\n",
    "\n",
    "\n",
    "# ENGLISH - FINNISH\n",
    "source_translation['translation'] = clean(source_translation['translation'], \n",
    "                                          lower = True, \n",
    "                                           remove_char = True,\n",
    "                                           remove_stop = True,\n",
    "                                            lemmatize = True,\n",
    "                                            stemmer = False,\n",
    "                                            english = False)\n",
    "\n",
    "source_translation['source'] = clean(source_translation['source'], \n",
    "                                          lower = True, \n",
    "                                           remove_char = True,\n",
    "                                           remove_stop = True,\n",
    "                                            lemmatize = True,\n",
    "                                            stemmer = False,\n",
    "                                            english = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turn pineapple dog character befitting roy lic...</td>\n",
       "      <td>voit muuttaa itsesi ananasta  koirasta roy lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>also shot three men two XX year old one XX yea...</td>\n",
       "      <td>my s ammuttiin kolme miest   kaksi XX vuotiait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>information stored cash register anyway whethe...</td>\n",
       "      <td>tiedot tallennetaan kassakoneisiin tapauksessa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xinhua say trace hydrochlorothiazide diuretic ...</td>\n",
       "      <td>xinhua kertoo  ett  xinyin n ytteest  sunnunta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macdonald brought board cbc commentary team pr...</td>\n",
       "      <td>voitaisiin kuulla cbd  n kommenttitiimin toimi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  turn pineapple dog character befitting roy lic...   \n",
       "1  also shot three men two XX year old one XX yea...   \n",
       "2  information stored cash register anyway whethe...   \n",
       "3  xinhua say trace hydrochlorothiazide diuretic ...   \n",
       "4  macdonald brought board cbc commentary team pr...   \n",
       "\n",
       "                                           reference  \n",
       "0  voit muuttaa itsesi ananasta  koirasta roy lic...  \n",
       "1  my s ammuttiin kolme miest   kaksi XX vuotiait...  \n",
       "2  tiedot tallennetaan kassakoneisiin tapauksessa...  \n",
       "3  xinhua kertoo  ett  xinyin n ytteest  sunnunta...  \n",
       "4  voitaisiin kuulla cbd  n kommenttitiimin toimi...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_reference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>turn pineapple dog character befitting roy lic...</td>\n",
       "      <td>voit muuttaa itsesi ananakseksi  koiraksi hahm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>also shot three men two XX year old one XX yea...</td>\n",
       "      <td>my s kolmea miest  ammuttiin  kahta XX vuotias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>information stored cash register anyway whethe...</td>\n",
       "      <td>tiedot kuitenkin tallentuvat kassoilla tapauks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xinhua say trace hydrochlorothiazide diuretic ...</td>\n",
       "      <td>xinhua kertoo  ett  xinyin sunnuntaina antamas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macdonald brought board cbc commentary team pr...</td>\n",
       "      <td>macdonaldin  tuli cbc n selostajatiimiin tuoma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  turn pineapple dog character befitting roy lic...   \n",
       "1  also shot three men two XX year old one XX yea...   \n",
       "2  information stored cash register anyway whethe...   \n",
       "3  xinhua say trace hydrochlorothiazide diuretic ...   \n",
       "4  macdonald brought board cbc commentary team pr...   \n",
       "\n",
       "                                         translation  \n",
       "0  voit muuttaa itsesi ananakseksi  koiraksi hahm...  \n",
       "1  my s kolmea miest  ammuttiin  kahta XX vuotias...  \n",
       "2  tiedot kuitenkin tallentuvat kassoilla tapauks...  \n",
       "3  xinhua kertoo  ett  xinyin sunnuntaina antamas...  \n",
       "4  macdonaldin  tuli cbc n selostajatiimiin tuoma...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_translation.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaBSE\n",
    "\n",
    "https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html \\\n",
    "https://arxiv.org/abs/2007.01852 \\\n",
    "https://tfhub.dev/google/LaBSE/1 \\\n",
    "https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
    "\n",
    "\\\n",
    "Pre-trained Model: https://huggingface.co/sentence-transformers/LaBSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For similarity between sentences, an L2-norm is recommended before calculating the similarity\n",
    "def similarity(embeddings_1, embeddings_2):\n",
    "    normalized_embeddings_1 = F.normalize(embeddings_1, p=2)\n",
    "    normalized_embeddings_2 = F.normalize(embeddings_2, p=2)\n",
    "    return torch.matmul(\n",
    "        normalized_embeddings_1, normalized_embeddings_2.transpose(0, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sentence-transformers/LaBSE were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "# model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "# model = model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = list(source_reference['source'].head(500))\n",
    "references = list(source_reference['reference'].head(500))\n",
    "translations = list(source_translation['translation'].head(500))\n",
    "\n",
    "# german_source = list(deen_reference['source'])\n",
    "# english_reference = list(deen_reference['reference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_inputs = tokenizer(sources, return_tensors=\"pt\", padding=True)\n",
    "reference_inputs = tokenizer(references, return_tensors=\"pt\", padding=True)\n",
    "translation_inputs = tokenizer(translations, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    source_outputs = model(**source_inputs)\n",
    "    reference_outputs = model(**reference_inputs)\n",
    "    translation_outputs = model(**translation_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the sentence embeddings, use the pooler output\n",
    "source_embeddings = source_outputs.pooler_output\n",
    "reference_embeddings = reference_outputs.pooler_output\n",
    "translation_embeddings = translation_outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_reference = similarity(reference_embeddings, source_embeddings)\n",
    "diagonal_reference = pd.Series(tf.linalg.tensor_diag_part(matrix_reference))\n",
    "\n",
    "matrix_translation = similarity(translation_embeddings, source_embeddings)\n",
    "diagonal_translation = pd.Series(tf.linalg.tensor_diag_part(matrix_translation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagonal of the embedding matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([diagonal_reference, diagonal_translation, corpus['z-score'].head(500), \n",
    "                    corpus['avg-score'].head(500)], axis = 1)\n",
    "result.columns = ['source_reference_similarity', 'source_translation_similarity', 'z-score', 'avg-score']\n",
    "result['difference_similarity'] = result['source_reference_similarity'] - result['source_translation_similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : CHINESE   |  Reference and Translation : ENGLISH\n",
      "Pearson correlation difference_similarity and z-score: \n",
      "0.09269746386076858\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.30105157682509415\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.16196237654836318\n"
     ]
    }
   ],
   "source": [
    "print('Source : CHINESE   |  Reference and Translation : ENGLISH')\n",
    "print('Pearson correlation difference_similarity and z-score: ')\n",
    "print(result[['z-score', 'difference_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : ENGLISH   |  Reference and Translation : CHINESE\n",
      "Pearson correlation difference_similarity and z-score: \n",
      "0.004173359039506843\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.23716163737944085\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.11737332024675519\n"
     ]
    }
   ],
   "source": [
    "print('Source : ENGLISH   |  Reference and Translation : CHINESE')\n",
    "print('Pearson correlation difference_similarity and z-score: ')\n",
    "print(result[['z-score', 'difference_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : ENGLISH   |  Reference and Translation : FINNISH\n",
      "Pearson correlation difference_similarity and z-score: \n",
      "-0.14494737709508357\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.19488241594825306\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.11780494534551317\n"
     ]
    }
   ],
   "source": [
    "print('Source : ENGLISH   |  Reference and Translation : FINNISH')\n",
    "print('Pearson correlation difference_similarity and z-score: ')\n",
    "print(result[['z-score', 'difference_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entire embedding vector for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7786, 0.1385, 0.1194,  ..., 0.1172, 0.1874, 0.1633],\n",
       "        [0.0607, 0.8447, 0.1732,  ..., 0.1481, 0.1821, 0.1622],\n",
       "        [0.0430, 0.2108, 0.7832,  ..., 0.1987, 0.1531, 0.0591],\n",
       "        ...,\n",
       "        [0.2070, 0.1215, 0.2416,  ..., 0.7976, 0.2308, 0.1462],\n",
       "        [0.2002, 0.1702, 0.0799,  ..., 0.2109, 0.8104, 0.3737],\n",
       "        [0.0175, 0.1822, 0.1830,  ..., 0.1495, 0.2263, 0.7588]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7575, 0.1540, 0.1176,  ..., 0.1483, 0.1901, 0.1483],\n",
       "        [0.0538, 0.8251, 0.1684,  ..., 0.1205, 0.1906, 0.1506],\n",
       "        [0.0645, 0.2404, 0.8107,  ..., 0.1991, 0.0960, 0.0617],\n",
       "        ...,\n",
       "        [0.2051, 0.0873, 0.2847,  ..., 0.6929, 0.2073, 0.0956],\n",
       "        [0.1859, 0.1360, 0.0776,  ..., 0.2224, 0.7727, 0.3438],\n",
       "        [0.0725, 0.1919, 0.1693,  ..., 0.1600, 0.3125, 0.7768]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888775724611849"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([matrix_reference[0].tolist()], [matrix_translation[0].tolist()])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos = []\n",
    "for i in range(len(matrix_reference)):\n",
    "    cos.append(cosine_similarity([matrix_reference[i].tolist()], [matrix_translation[i].tolist()])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_scores</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988878</td>\n",
       "      <td>-0.286195</td>\n",
       "      <td>34.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.547076</td>\n",
       "      <td>58.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.973626</td>\n",
       "      <td>1.122476</td>\n",
       "      <td>74.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.980316</td>\n",
       "      <td>0.383095</td>\n",
       "      <td>53.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.975524</td>\n",
       "      <td>-0.493065</td>\n",
       "      <td>32.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cosine_scores   z-score  avg-score\n",
       "0       0.988878 -0.286195      34.20\n",
       "1       0.997500  0.547076      58.40\n",
       "2       0.973626  1.122476      74.60\n",
       "3       0.980316  0.383095      53.60\n",
       "4       0.975524 -0.493065      32.25"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.concat([pd.Series(cos), corpus['z-score'].head(500), corpus['avg-score'].head(500)], axis = 1)\n",
    "result.columns = ['cosine_scores', 'z-score', 'avg-score']\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : CHINESE   |  Reference and Translation : ENGLISH\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.4507465848338922\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.32659983086897115\n"
     ]
    }
   ],
   "source": [
    "print('Source : CHINESE   |  Reference and Translation : ENGLISH')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'cosine_scores']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'cosine_scores']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : ENGLISH   |  Reference and Translation : CHINESE\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.2838280909635055\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.22439300379231272\n"
     ]
    }
   ],
   "source": [
    "print('Source : ENGLISH   |  Reference and Translation : CHINESE')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'cosine_scores']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'cosine_scores']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : ENGLISH   |  Reference and Translation : FINNISH\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.29150711128441614\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.21189399434259404\n"
     ]
    }
   ],
   "source": [
    "print('Source : ENGLISH   |  Reference and Translation : FINNISH')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'cosine_scores']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'cosine_scores']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result[['source_reference_similarity', 'source_translation_similarity', 'z-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['z-score'], axis=1)\n",
    "y = data['z-score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_regressor = LinearRegression()\n",
    "baseline_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = baseline_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R^2 score on test set : 0.14687139609738986\n"
     ]
    }
   ],
   "source": [
    "baseline_r2_test = baseline_regressor.score(X_test, y_test)\n",
    "\n",
    "print(f'Baseline R^2 score on test set : {baseline_r2_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred\n",
    "baseline_corr_train, baseline_corr_train_pvalue = pearsonr(y_train, cos_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
