{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Project\n",
    "\n",
    "### NOVA IMS MT Metrics Shared Task\n",
    "\n",
    "**Group members:**\n",
    "- Lorenzo Pigozzi\t--- m20200745\n",
    "- Davide Farinati\n",
    "- Antonio\n",
    "- Luis Reis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries and corpora <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# word's preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import jieba\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing the corpora\n",
    "# cs_en = pd.read_csv('corpus\\cs-en\\scores.csv')\n",
    "# de_en = pd.read_csv('corpus\\de-en\\scores.csv')\n",
    "# ru_en = pd.read_csv('corpus\\scores_ru-en.csv')\n",
    "zh_en = pd.read_csv('corpus\\zh-en\\scores.csv')\n",
    "# en_fi = pd.read_csv('corpus\\en-fi\\scores.csv')\n",
    "# en_zh = pd.read_csv('corpus\\en-zh\\scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。</td>\n",
       "      <td>His character is good for the British horse, b...</td>\n",
       "      <td>He's a lively character which is good for Brit...</td>\n",
       "      <td>0.625559</td>\n",
       "      <td>92.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。</td>\n",
       "      <td>A 28 chef, who has just moved to San Francisco...</td>\n",
       "      <td>A 28-year-old chef who had recently moved to S...</td>\n",
       "      <td>0.550952</td>\n",
       "      <td>92.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...</td>\n",
       "      <td>Last year, officials said Mr. Hooker's team ha...</td>\n",
       "      <td>Last year, officials said, Mr. Hooker's team c...</td>\n",
       "      <td>0.540814</td>\n",
       "      <td>89.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。</td>\n",
       "      <td>It is particularly interesting to note the gov...</td>\n",
       "      <td>Especially savory are the accounts of the gove...</td>\n",
       "      <td>-0.793944</td>\n",
       "      <td>49.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。</td>\n",
       "      <td>However, from the 1990s to the present, human ...</td>\n",
       "      <td>However, ever since the 1990s, a total of 18 h...</td>\n",
       "      <td>0.046532</td>\n",
       "      <td>77.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0             他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。   \n",
       "1                 近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。   \n",
       "2  去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...   \n",
       "3   尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。   \n",
       "4         不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。   \n",
       "\n",
       "                                           reference  \\\n",
       "0  His character is good for the British horse, b...   \n",
       "1  A 28 chef, who has just moved to San Francisco...   \n",
       "2  Last year, officials said Mr. Hooker's team ha...   \n",
       "3  It is particularly interesting to note the gov...   \n",
       "4  However, from the 1990s to the present, human ...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  He's a lively character which is good for Brit...  0.625559      92.75   \n",
       "1  A 28-year-old chef who had recently moved to S...  0.550952      92.00   \n",
       "2  Last year, officials said, Mr. Hooker's team c...  0.540814      89.00   \n",
       "3  Especially savory are the accounts of the gove... -0.793944      49.50   \n",
       "4  However, ever since the 1990s, a total of 18 h...  0.046532      77.50   \n",
       "\n",
       "   annotators  \n",
       "0           4  \n",
       "1           4  \n",
       "2           5  \n",
       "3           4  \n",
       "4           4  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = zh_en.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. Pre-processing <a class=\"anchor\" id=\"3.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the necessary variables for the baseline\n",
    "source_reference = corpus[['source','reference']]\n",
    "source_translation = corpus[['source','translation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。</td>\n",
       "      <td>His character is good for the British horse, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。</td>\n",
       "      <td>A 28 chef, who has just moved to San Francisco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...</td>\n",
       "      <td>Last year, officials said Mr. Hooker's team ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。</td>\n",
       "      <td>It is particularly interesting to note the gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。</td>\n",
       "      <td>However, from the 1990s to the present, human ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0             他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。   \n",
       "1                 近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。   \n",
       "2  去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...   \n",
       "3   尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。   \n",
       "4         不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。   \n",
       "\n",
       "                                           reference  \n",
       "0  His character is good for the British horse, b...  \n",
       "1  A 28 chef, who has just moved to San Francisco...  \n",
       "2  Last year, officials said Mr. Hooker's team ha...  \n",
       "3  It is particularly interesting to note the gov...  \n",
       "4  However, from the 1990s to the present, human ...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_reference.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Cleaning <a class=\"anchor\" id=\"3.1.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text_list,\n",
    "          lower = False,\n",
    "          keep_numbers = False,\n",
    "          keep_expression = False,\n",
    "          remove_char = False,\n",
    "          remove_stop = False,\n",
    "          remove_tag = False,\n",
    "          lemmatize = False,\n",
    "          stemmer = False,\n",
    "          english = True\n",
    "          ):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    if english:\n",
    "        lang = 'english'\n",
    "    else:\n",
    "        lang = 'german'\n",
    "    \n",
    "    stop = set(stopwords.words(lang))\n",
    "    stem = SnowballStemmer(lang)\n",
    "    \n",
    "    updates = []\n",
    "    for j in tqdm(range(len(text_list))):\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        if lower:\n",
    "            text = text.lower()\n",
    "            \n",
    "        #KEEP NUMBERS AS TOKENS\n",
    "        if keep_numbers:\n",
    "            text = re.sub(\"[\\d+]\", 'NUMBER', text)\n",
    "        \n",
    "        #KEEP '?' and '!' AS TOKENS\n",
    "        if keep_expression:\n",
    "            text = re.sub(\"[\\?|\\!]\", 'EXPRESSION', text)\n",
    "            \n",
    "        #REMOVE THAT IS NOT TEXT\n",
    "        if remove_char:\n",
    "            text = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "            \n",
    "        #REMOVE TAGS\n",
    "        if remove_tag:\n",
    "            text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        #REMOVE STOP WORDS\n",
    "        if remove_stop:\n",
    "            text = ' '.join([word for word in text.split(' ') if word not in stop])\n",
    "        \n",
    "        #LEMMATIZATION\n",
    "        if lemmatize:\n",
    "            if english:\n",
    "                lemma = WordNetLemmatizer()\n",
    "                text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "#             else:\n",
    "#                 lemma = libvoikko.Voikko(u\"fi\")\n",
    "#                 text = \" \".join(lemma.analyze(word)[0]['BASEFORM'] for word in text.split())\n",
    "        \n",
    "        #STEMMER\n",
    "        if stemmer:\n",
    "            text = \" \".join(stem.stem(word) for word in text.split())\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def clean_ch(text_list, keep_numbers=False, remove_punctuation=False, remove_stop = False, stopwords_set='merged'):\n",
    "    \"\"\"\n",
    "    Function that removes chinese stopwords\n",
    "    \n",
    "    :param stopwords_set: remove words of both sets (merged), just the 1st (fst) or just the second (snd) \n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    \n",
    "    zh_stopwords1 = [line.strip() for line in open('chinese_stopwords/chinese_stopwords1.txt', 'r', encoding='utf-8').readlines()]\n",
    "    zh_stopwords2 = [line.strip() for line in open('chinese_stopwords/chinese_stopwords2.txt', 'r', encoding='utf-8').readlines()]\n",
    "    \n",
    "    if stopwords_set == 'merged':\n",
    "        stop = list(set(zh_stopwords1 + zh_stopwords2))\n",
    "    elif stopwords_set == 'fst':\n",
    "        stop = zh_stopwords1\n",
    "    elif stopwords_set == 'snd':\n",
    "        stop = zh_stopwords2\n",
    "\n",
    "    for j in range(len(text_list)):\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #KEEP NUMBERS AS TOKENS\n",
    "        if keep_numbers:\n",
    "            text = re.sub(\"[\\d+]\", 'X', text)\n",
    "        \n",
    "        # REMOVE PUNCTUATION\n",
    "        if remove_punctuation:\n",
    "            # https://stackoverflow.com/questions/36640587/how-to-remove-chinese-punctuation-in-python\n",
    "            punc = \"！？｡。＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.\"\n",
    "            text = re.sub(r\"[%s]+\" %punc, \"\", text)\n",
    "        \n",
    "        # REMOVE STOP WORDS\n",
    "        if remove_stop:\n",
    "            pretext = text\n",
    "            text = ' '.join([word for word in jieba.cut(text) if word not in stop])\n",
    "            \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def update_df(dataframe, list_updated):\n",
    "    dataframe.update(pd.DataFrame({\"Text\": list_updated}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。</td>\n",
       "      <td>His character is good for the British horse, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。</td>\n",
       "      <td>A 28 chef, who has just moved to San Francisco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...</td>\n",
       "      <td>Last year, officials said Mr. Hooker's team ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。</td>\n",
       "      <td>It is particularly interesting to note the gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。</td>\n",
       "      <td>However, from the 1990s to the present, human ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0             他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。   \n",
       "1                 近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。   \n",
       "2  去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...   \n",
       "3   尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。   \n",
       "4         不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。   \n",
       "\n",
       "                                           reference  \n",
       "0  His character is good for the British horse, b...  \n",
       "1  A 28 chef, who has just moved to San Francisco...  \n",
       "2  Last year, officials said Mr. Hooker's team ha...  \n",
       "3  It is particularly interesting to note the gov...  \n",
       "4  However, from the 1990s to the present, human ...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_reference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。</td>\n",
       "      <td>He's a lively character which is good for Brit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。</td>\n",
       "      <td>A 28-year-old chef who had recently moved to S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...</td>\n",
       "      <td>Last year, officials said, Mr. Hooker's team c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。</td>\n",
       "      <td>Especially savory are the accounts of the gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。</td>\n",
       "      <td>However, ever since the 1990s, a total of 18 h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0             他性格活泼，这对英国赛马来说是好事，但是除此之外，他还是一位不可思议的骑师。   \n",
       "1                 近日刚搬至旧金山的一位28岁厨师本周被发现死于当地一家商场的楼梯间。   \n",
       "2  去年，有官员表示，胡克先生的团队所得出的结论是针对伊斯兰国炼油厂的空袭并未大幅削减恐怖组织的...   \n",
       "3   尤其值得玩味的是政府对于饥饿民众们的回应，比如总统市民赫伯特·胡佛“别人的事我可管不了”的态度。   \n",
       "4         不过，从20世纪90年代至今，人类共进行了18次火星探测，而月球探测只进行了14次。   \n",
       "\n",
       "                                         translation  \n",
       "0  He's a lively character which is good for Brit...  \n",
       "1  A 28-year-old chef who had recently moved to S...  \n",
       "2  Last year, officials said, Mr. Hooker's team c...  \n",
       "3  Especially savory are the accounts of the gove...  \n",
       "4  However, ever since the 1990s, a total of 18 h...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_translation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347d88a7b8af4668ab190d092fa93bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_reference['source'] = clean_ch(source_reference['source'], \n",
    "                                keep_numbers = False,\n",
    "                                remove_punctuation = False,\n",
    "                                remove_stop = True,\n",
    "                                stopwords_set = 'snd')\n",
    "\n",
    "source_reference['reference'] = clean(source_reference['reference'], \n",
    "                                      lower = True, \n",
    "                                      remove_char = True,\n",
    "                                      remove_stop = True,\n",
    "                                      lemmatize = True,\n",
    "                                      stemmer = False,\n",
    "                                      english = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56194f69f2746049d86a643f2806352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26419.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_translation['source'] = clean_ch(source_translation['source'], \n",
    "                                keep_numbers = False,\n",
    "                                remove_punctuation = False,\n",
    "                                remove_stop = True,\n",
    "                                stopwords_set = 'snd')\n",
    "\n",
    "source_translation['translation'] = clean(source_translation['translation'], \n",
    "                                          lower = True, \n",
    "                                           remove_char = True,\n",
    "                                           remove_stop = True,\n",
    "                                            lemmatize = True,\n",
    "                                            stemmer = False,\n",
    "                                            english = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>性格 活泼 英国 赛马 好事 一位 不可思议 骑师</td>\n",
       "      <td>lively character good british racing incredibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>近日 刚 搬 旧金山 一位 28 岁 厨师 本周 发现 死 一家 商场 楼梯间</td>\n",
       "      <td>year old chef recently moved san francisco fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>去年 官员 表示 胡克 先生 团队 得出 结论 伊斯兰 国 炼油厂 空袭 并未 大幅 削减 ...</td>\n",
       "      <td>last year official said mr hooker team conclud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>尤其 值得 玩味 政府 饥饿 民众 回应 总统 市民 赫伯特 · 胡佛 “ 事 管不了 ” 态度</td>\n",
       "      <td>especially savory account government response ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 世纪 90 年代 人类 进行 18 次 火星 探测 月球 探测 进行 14 次</td>\n",
       "      <td>however ever since total human exploration car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0                          性格 活泼 英国 赛马 好事 一位 不可思议 骑师   \n",
       "1            近日 刚 搬 旧金山 一位 28 岁 厨师 本周 发现 死 一家 商场 楼梯间   \n",
       "2  去年 官员 表示 胡克 先生 团队 得出 结论 伊斯兰 国 炼油厂 空袭 并未 大幅 削减 ...   \n",
       "3   尤其 值得 玩味 政府 饥饿 民众 回应 总统 市民 赫伯特 · 胡佛 “ 事 管不了 ” 态度   \n",
       "4         20 世纪 90 年代 人类 进行 18 次 火星 探测 月球 探测 进行 14 次   \n",
       "\n",
       "                                         translation  \n",
       "0  lively character good british racing incredibl...  \n",
       "1  year old chef recently moved san francisco fou...  \n",
       "2  last year official said mr hooker team conclud...  \n",
       "3  especially savory account government response ...  \n",
       "4  however ever since total human exploration car...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_translation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>性格 活泼 英国 赛马 好事 一位 不可思议 骑师</td>\n",
       "      <td>character good british horse addition incredib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>近日 刚 搬 旧金山 一位 28 岁 厨师 本周 发现 死 一家 商场 楼梯间</td>\n",
       "      <td>chef moved san francisco found dead stair loca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>去年 官员 表示 胡克 先生 团队 得出 结论 伊斯兰 国 炼油厂 空袭 并未 大幅 削减 ...</td>\n",
       "      <td>last year official said mr hooker team conclud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>尤其 值得 玩味 政府 饥饿 民众 回应 总统 市民 赫伯特 · 胡佛 “ 事 管不了 ” 态度</td>\n",
       "      <td>particularly interesting note government respo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 世纪 90 年代 人类 进行 18 次 火星 探测 月球 探测 进行 14 次</td>\n",
       "      <td>however present human being carried mar probe ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0                          性格 活泼 英国 赛马 好事 一位 不可思议 骑师   \n",
       "1            近日 刚 搬 旧金山 一位 28 岁 厨师 本周 发现 死 一家 商场 楼梯间   \n",
       "2  去年 官员 表示 胡克 先生 团队 得出 结论 伊斯兰 国 炼油厂 空袭 并未 大幅 削减 ...   \n",
       "3   尤其 值得 玩味 政府 饥饿 民众 回应 总统 市民 赫伯特 · 胡佛 “ 事 管不了 ” 态度   \n",
       "4         20 世纪 90 年代 人类 进行 18 次 火星 探测 月球 探测 进行 14 次   \n",
       "\n",
       "                                           reference  \n",
       "0  character good british horse addition incredib...  \n",
       "1  chef moved san francisco found dead stair loca...  \n",
       "2  last year official said mr hooker team conclud...  \n",
       "3  particularly interesting note government respo...  \n",
       "4  however present human being carried mar probe ...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_reference.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaBSE\n",
    "\n",
    "https://ai.googleblog.com/2020/08/language-agnostic-bert-sentence.html \\\n",
    "https://arxiv.org/abs/2007.01852 \\\n",
    "https://tfhub.dev/google/LaBSE/1 \\\n",
    "https://pytorch.org/docs/stable/generated/torch.matmul.html\n",
    "\n",
    "\\\n",
    "Pre-trained Model: https://huggingface.co/sentence-transformers/LaBSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "# from transformers import BertModel, BertTokenizerFast\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For similarity between sentences, an L2-norm is recommended before calculating the similarity\n",
    "def similarity(embeddings_1, embeddings_2):\n",
    "    normalized_embeddings_1 = F.normalize(embeddings_1, p=2)\n",
    "    normalized_embeddings_2 = F.normalize(embeddings_2, p=2)\n",
    "    return torch.matmul(\n",
    "        normalized_embeddings_1, normalized_embeddings_2.transpose(0, 1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at sentence-transformers/LaBSE were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "# model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "# model = model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/LaBSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = list(source_reference['source'].head(500))\n",
    "references = list(source_reference['reference'].head(500))\n",
    "translations = list(source_translation['translation'].head(500))\n",
    "\n",
    "# german_source = list(deen_reference['source'])\n",
    "# english_reference = list(deen_reference['reference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_inputs = tokenizer(sources, return_tensors=\"pt\", padding=True)\n",
    "reference_inputs = tokenizer(references, return_tensors=\"pt\", padding=True)\n",
    "translation_inputs = tokenizer(translations, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    source_outputs = model(**source_inputs)\n",
    "    reference_outputs = model(**reference_inputs)\n",
    "    translation_outputs = model(**translation_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the sentence embeddings, use the pooler output\n",
    "source_embeddings = source_outputs.pooler_output\n",
    "reference_embeddings = reference_outputs.pooler_output\n",
    "translation_embeddings = translation_outputs.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_reference = similarity(source_embeddings, reference_embeddings)\n",
    "diagonal_reference = pd.Series(tf.linalg.tensor_diag_part(matrix_reference))\n",
    "\n",
    "matrix_translation = similarity(source_embeddings, translation_embeddings)\n",
    "diagonal_translation = pd.Series(tf.linalg.tensor_diag_part(matrix_translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([diagonal_reference, diagonal_translation, corpus['z-score'].head(500), \n",
    "                    corpus['avg-score'].head(500)], axis = 1)\n",
    "result.columns = ['source_reference_similarity', 'source_translation_similarity', 'z-score', 'avg-score']\n",
    "result['difference_similarity'] = result['source_reference_similarity'] - result['source_translation_similarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : ENGLISH   |  Reference and Translation : CHINESE\n",
      "Pearson correlation difference_similarity and z-score: \n",
      "0.020196960018330712\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.22479069539029461\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.098239157536945\n"
     ]
    }
   ],
   "source": [
    "print('Source : ENGLISH   |  Reference and Translation : CHINESE')\n",
    "print('Pearson correlation difference_similarity and z-score: ')\n",
    "print(result[['z-score', 'difference_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : CHINESE   |  Reference and Translation : ENGLISH\n",
      "Pearson correlation difference_similarity and z-score: \n",
      "0.09269746386076858\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.30105157682509415\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.16196237654836318\n"
     ]
    }
   ],
   "source": [
    "print('Source : CHINESE   |  Reference and Translation : ENGLISH')\n",
    "print('Pearson correlation difference_similarity and z-score: ')\n",
    "print(result[['z-score', 'difference_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHINESE-ENGLISH\n",
      "Pearson correlation difference_similarity and z-score: \n",
      "0.06076862915462028\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "Pearson correlation source_translation_similarity and z-score: \n",
      "0.24995177828414075\n",
      "---------------------------------------------------------------------\n",
      "Kendall correlation source_translation_similarity and z-score: \n",
      "0.10516926263437275\n"
     ]
    }
   ],
   "source": [
    "print('Source : CHINESE   |  Reference and Translation : ENGLISH')\n",
    "print('Pearson correlation difference_similarity and z-score: ')\n",
    "print(result[['z-score', 'difference_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Pearson correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='pearson').iloc[1:2,:1].values[0][0])\n",
    "print('---------------------------------------------------------------------')\n",
    "print('Kendall correlation source_translation_similarity and z-score: ')\n",
    "print(result[['z-score', 'source_translation_similarity']].corr(method='kendall').iloc[1:2,:1].values[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = result[['source_reference_similarity', 'source_translation_similarity', 'z-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['z-score'], axis=1)\n",
    "y = data['z-score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_regressor = LinearRegression()\n",
    "baseline_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = baseline_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R^2 score on test set : 0.14687139609738986\n"
     ]
    }
   ],
   "source": [
    "baseline_r2_test = baseline_regressor.score(X_test, y_test)\n",
    "\n",
    "print(f'Baseline R^2 score on test set : {baseline_r2_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred\n",
    "baseline_corr_train, baseline_corr_train_pvalue = pearsonr(y_train, cos_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
