{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8a6ce8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04457967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.stats import pearsonr, kendalltau\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b064483",
   "metadata": {
    "id": "jA_9c3SpLTUn"
   },
   "source": [
    "# Data Importing and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54babd00",
   "metadata": {
    "id": "nU_gOCWtF8XY"
   },
   "outputs": [],
   "source": [
    "files = os.listdir('corpus')\n",
    "files.remove('.DS_Store')\n",
    "files.remove('scores_ru-en.csv')\n",
    "scaler = MinMaxScaler()\n",
    "for file_ in files:\n",
    "  name = file_.split('-')[0] + file_.split('-')[1]\n",
    "  vars()[name] = pd.read_csv(os.path.join('corpus', file_, 'scores.csv'))\n",
    "  vars()[name].drop(columns = ['source', 'annotators', 'z-score'], inplace = True)\n",
    "  vars()[name]['avg-score'] = scaler.fit_transform(vars()[name]['avg-score'].values.reshape(-1,1)) #normalizing values betwewen 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ace494a",
   "metadata": {
    "id": "EcUEx6elHvwd"
   },
   "outputs": [],
   "source": [
    "english = csen.copy()\n",
    "for df in [deen, ruen, zhen]:\n",
    "  english = english.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c371bb52",
   "metadata": {
    "id": "8ziEKCv4LFwE"
   },
   "outputs": [],
   "source": [
    "finnish = enfi.copy()\n",
    "chinese = enzh.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53c059",
   "metadata": {
    "id": "NjBupUyDLNRa"
   },
   "source": [
    "# Train, Dev & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17829321",
   "metadata": {
    "id": "qZKkQkBNLSYT"
   },
   "outputs": [],
   "source": [
    "en_train, en_dev = train_test_split(english, shuffle = True, test_size = 0.2, random_state = 7)\n",
    "en_dev, en_test = train_test_split(en_dev, shuffle = True, test_size = 0.5, random_state = 7)\n",
    "\n",
    "fin_train, fin_dev = train_test_split(finnish, shuffle = True, test_size = 0.2, random_state = 7)\n",
    "fin_dev, fin_test = train_test_split(fin_dev, shuffle = True, test_size = 0.5, random_state = 7)\n",
    "\n",
    "ch_train, ch_dev = train_test_split(chinese, shuffle = True, test_size = 0.2, random_state = 7)\n",
    "ch_dev, ch_test = train_test_split(ch_dev, shuffle = True, test_size = 0.5, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca169350",
   "metadata": {},
   "source": [
    "# Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3f1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bea4732",
   "metadata": {},
   "source": [
    "# Baseline encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_encoder = CountVectorizer(max_features = 5000)#settting limit for computational reasons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a6fbb5",
   "metadata": {},
   "source": [
    "# Correlation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a760af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(y_train, pred_train, y_dev, pred_dev, y_test, pred_test):\n",
    "\n",
    "    corr_train, corr_train_pvalue = pearsonr(y_train, pred_train)\n",
    "    corr_dev, corr_dev_pvalue = pearsonr(y_dev, pred_dev)\n",
    "    corr_test, corr_test_pvalue = pearsonr(y_test, pred_test)\n",
    "\n",
    "    corr_ktau_train, corr_ktau_train_pvalue = kendalltau(y_train, pred_train)\n",
    "    corr_ktau_dev, corr_ktau_dev_pvalue = kendalltau(y_dev, pred_dev)\n",
    "    corr_ktau_test, corr_ktau_test_pvalue = kendalltau(y_test, pred_test)\n",
    "    \n",
    "    print(f'Pearson correlation between cosine similarity and score on training set: {corr_train} (p-value < 0.001: {corr_train_pvalue < 0.001}); and Kendall Tau: {corr_ktau_train} (p-value < 0.001: {corr_ktau_train_pvalue < 0.001})')\n",
    "    print(f'Pearson correlation between cosine similarity and score on development set: {corr_dev} (p-value < 0.001: {corr_dev_pvalue < 0.001}); and Kendall Tau: {corr_ktau_dev} (p-value < 0.001: {corr_ktau_dev_pvalue < 0.001})')\n",
    "    print(f'Pearson correlation between cosine similarity and score on test set: {corr_test} (p-value < 0.001: {corr_test_pvalue < 0.001}); and Kendall Tau: {corr_ktau_test} (p-value < 0.001: {corr_ktau_test_pvalue < 0.001})')\n",
    "    \n",
    "    return corr_train, corr_dev, corr_test, corr_ktau_train, corr_ktau_dev, corr_ktau_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefae8e1",
   "metadata": {},
   "source": [
    "# Grid search in cleaning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e27a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5954     0.656667\n",
       "1045     0.855000\n",
       "14106    1.000000\n",
       "8575     0.770000\n",
       "6739     0.790000\n",
       "           ...   \n",
       "2190     0.475000\n",
       "10742    1.000000\n",
       "16400    0.270000\n",
       "7295     0.620000\n",
       "10346    0.405000\n",
       "Name: avg-score, Length: 62150, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_train['avg-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6004fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['en_train', 'en_dev', 'en_test']\n",
    "results = {}\n",
    "for cleaning in cleaning_configurations:    \n",
    "    for i,df in enumerate([en_train, en_dev, en_test]):\n",
    "        for column in ['reference', 'translation']:\n",
    "            encoded_df = names[i] + '_bl_encoded_' + column\n",
    "            \n",
    "            vars()[encoded_df] = clean(english[column], cleaning)\n",
    "            if i == 0:\n",
    "                vars()[encoded_df] = baseline_encoder.fit_transform(df[column]).todense()\n",
    "            else:\n",
    "                vars()[encoded_df] = baseline_encoder.transform(df[column]).todense()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    results[cleaning] = (correlation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0ebef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9dc84f2",
   "metadata": {},
   "source": [
    "# Graphical Visualization of results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
