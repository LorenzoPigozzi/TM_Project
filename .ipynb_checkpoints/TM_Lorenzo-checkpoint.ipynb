{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Project\n",
    "\n",
    "### NOVA IMS MT Metrics Shared Task\n",
    "\n",
    "**Group members:**\n",
    "- Lorenzo Pigozzi\t--- m20200745\n",
    "- Davide Farinati\n",
    "- Antonio\n",
    "- Luis Reis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**\n",
    "\n",
    "The goal of this project is to develop a metric that predicts the quality of a translation using the reference. \n",
    "\n",
    "\\\n",
    "**Evaluation**\\\n",
    "Your metric should correlate well with the existing quality assessments that you have in the above corpus.\n",
    "The one that we have so far are just the training sets, we will have a test set without the z-score, average score and annotators.\n",
    "Produce our own metric that will be compared with the existing ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "# **Table of Contents**\n",
    "\n",
    "1.\t[Importing libraries and corpora](#1)   \n",
    "2.\t[Brief Exploratory data analysis (EDA)](#2)       \n",
    "3.\t[Pre-processing](#3.)     \n",
    " 3.1. [Cleaning](#3.1.)\\\n",
    " 3.2. [Train-dev-test](#3.2.)\n",
    "4. [Metrics](#4.)\n",
    "5. [Modeling](#5.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\\\n",
    "Sklearn:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries and corpora <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# word's preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing the corpora\n",
    "cs_en = pd.read_csv('corpus\\cs-en\\scores.csv')\n",
    "de_en = pd.read_csv('corpus\\de-en\\scores.csv')\n",
    "ru_en = pd.read_csv('corpus\\scores_ru-en.csv')\n",
    "zh_en = pd.read_csv('corpus\\zh-en\\scores.csv')\n",
    "en_fi = pd.read_csv('corpus\\en-fi\\scores.csv')\n",
    "en_zh = pd.read_csv('corpus\\en-zh\\scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Brief Exploratory Data Analysis <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can turn yourself into a pineapple, a dog ...</td>\n",
       "      <td>Voit muuttaa itsesi ananasta, koirasta tai Roy...</td>\n",
       "      <td>Voit muuttaa itsesi ananakseksi, koiraksi tai ...</td>\n",
       "      <td>-0.286195</td>\n",
       "      <td>34.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Also shot were three men: two 29-year-olds and...</td>\n",
       "      <td>Myös ammuttiin kolme miestä: kaksi 29-vuotiait...</td>\n",
       "      <td>Myös kolmea miestä ammuttiin: kahta 29-vuotias...</td>\n",
       "      <td>0.547076</td>\n",
       "      <td>58.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The information is stored at the cash register...</td>\n",
       "      <td>Tiedot tallennetaan kassakoneisiin joka tapauk...</td>\n",
       "      <td>Tiedot kuitenkin tallentuvat kassoilla joka ta...</td>\n",
       "      <td>1.122476</td>\n",
       "      <td>74.60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xinhua says that there were traces of hydrochl...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin näytteestä oli sunn...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin sunnuntaina antamas...</td>\n",
       "      <td>0.383095</td>\n",
       "      <td>53.60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacDonald, who was brought on board CBC's comm...</td>\n",
       "      <td>Voitaisiin kuulla CBD: n kommenttitiimin toimi...</td>\n",
       "      <td>MacDonaldin, joka tuli CBC:n selostajatiimiin ...</td>\n",
       "      <td>-0.493065</td>\n",
       "      <td>32.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  You can turn yourself into a pineapple, a dog ...   \n",
       "1  Also shot were three men: two 29-year-olds and...   \n",
       "2  The information is stored at the cash register...   \n",
       "3  Xinhua says that there were traces of hydrochl...   \n",
       "4  MacDonald, who was brought on board CBC's comm...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Voit muuttaa itsesi ananasta, koirasta tai Roy...   \n",
       "1  Myös ammuttiin kolme miestä: kaksi 29-vuotiait...   \n",
       "2  Tiedot tallennetaan kassakoneisiin joka tapauk...   \n",
       "3  Xinhua kertoo, että Xinyin näytteestä oli sunn...   \n",
       "4  Voitaisiin kuulla CBD: n kommenttitiimin toimi...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Voit muuttaa itsesi ananakseksi, koiraksi tai ... -0.286195      34.20   \n",
       "1  Myös kolmea miestä ammuttiin: kahta 29-vuotias...  0.547076      58.40   \n",
       "2  Tiedot kuitenkin tallentuvat kassoilla joka ta...  1.122476      74.60   \n",
       "3  Xinhua kertoo, että Xinyin sunnuntaina antamas...  0.383095      53.60   \n",
       "4  MacDonaldin, joka tuli CBC:n selostajatiimiin ... -0.493065      32.25   \n",
       "\n",
       "   annotators  \n",
       "0           5  \n",
       "1           5  \n",
       "2           5  \n",
       "3           5  \n",
       "4           4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\\\n",
    "All the the Dataframes imported have 6 columns:\n",
    "- Sources: the original text in the original language\n",
    "- Reference: The correct translation\n",
    "- Translation: the translation that we will evaluate\n",
    "- Z-score: score of the translation normalized\n",
    "- Avg-score: score of the translation from 0 to 100\n",
    "- Annotators: number of annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of translations :  94657\n"
     ]
    }
   ],
   "source": [
    "print('Total number of translations : ',len(cs_en) + len(de_en) + len(ru_en) + len(zh_en) + len(en_fi) + len(en_zh) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea**\\\n",
    "Splitting the problem in 3:\n",
    "- estimate the translations from other languages to English\n",
    "- estimate the translations from English to Finnish\n",
    "- estimate the translations from English to Chinese\n",
    "\n",
    "\\\n",
    "Reason:\\\n",
    "Proably going forward we will need to have different preprocessing for English and for the other 2 languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3. Pre-processing <a class=\"anchor\" id=\"3.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uchopíte pak zbraň mezi své předloktí a rameno...</td>\n",
       "      <td>You will then grab the weapon between your for...</td>\n",
       "      <td>You then grasp the gun between your forearm an...</td>\n",
       "      <td>-0.675383</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ale je-li New York změna, pak je to také znovu...</td>\n",
       "      <td>But if New York is changed, then it's also a r...</td>\n",
       "      <td>But if New York is change, it is also reinvent...</td>\n",
       "      <td>-0.829403</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dlouho a intenzivně jsem během léta přemýšlel,...</td>\n",
       "      <td>I have been thinking over and over again over ...</td>\n",
       "      <td>I have thought long and hard over the course o...</td>\n",
       "      <td>0.803185</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Najdou si jiný způsob, jak někde podvádět.</td>\n",
       "      <td>They find another way to cheat somewhere.</td>\n",
       "      <td>They will find another way how to defraud others.</td>\n",
       "      <td>0.563149</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zpráva o výměně v čele prezidentovy administra...</td>\n",
       "      <td>The report on the replacement of the president...</td>\n",
       "      <td>The news of the replacement at the top of the ...</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Uchopíte pak zbraň mezi své předloktí a rameno...   \n",
       "1  Ale je-li New York změna, pak je to také znovu...   \n",
       "2  Dlouho a intenzivně jsem během léta přemýšlel,...   \n",
       "3         Najdou si jiný způsob, jak někde podvádět.   \n",
       "4  Zpráva o výměně v čele prezidentovy administra...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  You will then grab the weapon between your for...   \n",
       "1  But if New York is changed, then it's also a r...   \n",
       "2  I have been thinking over and over again over ...   \n",
       "3          They find another way to cheat somewhere.   \n",
       "4  The report on the replacement of the president...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  You then grasp the gun between your forearm an... -0.675383  60.000000   \n",
       "1  But if New York is change, it is also reinvent... -0.829403  44.000000   \n",
       "2  I have thought long and hard over the course o...  0.803185  96.500000   \n",
       "3  They will find another way how to defraud others.  0.563149  90.500000   \n",
       "4  The news of the replacement at the top of the ...  0.021549  74.666667   \n",
       "\n",
       "   annotators  \n",
       "0           3  \n",
       "1           2  \n",
       "2           2  \n",
       "3           2  \n",
       "4           3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the necessary variables for the baseline\n",
    "cs_en = cs_en[['reference','translation','avg-score']]\n",
    "de_en = de_en[['reference','translation','avg-score']]\n",
    "ru_en = ru_en[['reference','translation','avg-score']]\n",
    "zh_en = zh_en[['reference','translation','avg-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>avg-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will then grab the weapon between your for...</td>\n",
       "      <td>You then grasp the gun between your forearm an...</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But if New York is changed, then it's also a r...</td>\n",
       "      <td>But if New York is change, it is also reinvent...</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been thinking over and over again over ...</td>\n",
       "      <td>I have thought long and hard over the course o...</td>\n",
       "      <td>96.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They find another way to cheat somewhere.</td>\n",
       "      <td>They will find another way how to defraud others.</td>\n",
       "      <td>90.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The report on the replacement of the president...</td>\n",
       "      <td>The news of the replacement at the top of the ...</td>\n",
       "      <td>74.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  You will then grab the weapon between your for...   \n",
       "1  But if New York is changed, then it's also a r...   \n",
       "2  I have been thinking over and over again over ...   \n",
       "3          They find another way to cheat somewhere.   \n",
       "4  The report on the replacement of the president...   \n",
       "\n",
       "                                         translation  avg-score  \n",
       "0  You then grasp the gun between your forearm an...  60.000000  \n",
       "1  But if New York is change, it is also reinvent...  44.000000  \n",
       "2  I have thought long and hard over the course o...  96.500000  \n",
       "3  They will find another way how to defraud others.  90.500000  \n",
       "4  The news of the replacement at the top of the ...  74.666667  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the 4 datasets with English translations\n",
    "english_corpus = pd.concat([cs_en, de_en, ru_en, zh_en], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Cleaning <a class=\"anchor\" id=\"3.1.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text_list,\n",
    "          lower = False,\n",
    "          keep_numbers = False,\n",
    "          keep_expression = False,\n",
    "          remove_char = False,\n",
    "          remove_stop = False,\n",
    "          remove_tag = False,\n",
    "          lemmatize = False,\n",
    "          stemmer = False,\n",
    "          english = True\n",
    "          ):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    if english:\n",
    "        lang = 'english'\n",
    "    else:\n",
    "        lang = 'finnish'\n",
    "    \n",
    "    stop = set(stopwords.words(lang))\n",
    "    stem = SnowballStemmer(lang)\n",
    "    \n",
    "    updates = []\n",
    "    for j in tqdm(range(len(text_list))):\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        if lower:\n",
    "            text = text.lower()\n",
    "            \n",
    "        #KEEP NUMBERS AS TOKENS\n",
    "        if keep_numbers:\n",
    "            text = re.sub(\"[\\d+]\", 'NUMBER', text)\n",
    "        \n",
    "        #KEEP '?' and '!' AS TOKENS\n",
    "        if keep_expression:\n",
    "            text = re.sub(\"[\\?|\\!]\", 'EXPRESSION', text)\n",
    "            \n",
    "        #REMOVE THAT IS NOT TEXT\n",
    "        if remove_char:\n",
    "            text = re.sub(\"[^a-zA-Z]\", ' ', text)\n",
    "            \n",
    "        #REMOVE TAGS\n",
    "        if remove_tag:\n",
    "            text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        #REMOVE STOP WORDS\n",
    "        if remove_stop:\n",
    "            text = ' '.join([word for word in text.split(' ') if word not in stop])\n",
    "        \n",
    "        #LEMMATIZATION\n",
    "        if lemmatize:\n",
    "            if english:\n",
    "                lemma = WordNetLemmatizer()\n",
    "                text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "#             else:\n",
    "#                 lemma = libvoikko.Voikko(u\"fi\")\n",
    "#                 text = \" \".join(lemma.analyze(word)[0]['BASEFORM'] for word in text.split())\n",
    "        \n",
    "        #STEMMER\n",
    "        if stemmer:\n",
    "            text = \" \".join(stem.stem(word) for word in text.split())\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "def clean_zh_stopwords(text_list, stopwords_set='merged'):\n",
    "    \"\"\"\n",
    "    Function that removes chinese stopwords\n",
    "    \n",
    "    :param stopwords_set: remove words of both sets (merged), just the 1st (fst) or just the second (snd) \n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    \n",
    "    zh_stopwords1 = [line.strip() for line in open('chinese_stopwords/chinese_stopwords1.txt', 'r', encoding='utf-8').readlines()]\n",
    "    zh_stopwords2 = [line.strip() for line in open('chinese_stopwords/chinese_stopwords2.txt', 'r', encoding='utf-8').readlines()]\n",
    "    \n",
    "    if stopwords_set == 'merged':\n",
    "        stop = list(set(zh_stopwords1 + zh_stopwords2))\n",
    "    elif stopwords_set == 'fst':\n",
    "        stop = zh_stopwords1\n",
    "    elif stopwords_set == 'snd':\n",
    "        stop = zh_stopwords2\n",
    "        \n",
    "\n",
    "    for j in tqdm(range(len(text_list))):\n",
    "        text = text_list[j]\n",
    "        text = ' '.join([word for word in text.split(' ') if word not in stop])\n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "        \n",
    "    \n",
    "def update_df(dataframe, list_updated):\n",
    "    dataframe.update(pd.DataFrame({\"Text\": list_updated}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af1be478e8f4fb8889e5176d0a7d32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=77688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370e583274744dca9955c81018be91ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=77688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "english_cleaned = pd.DataFrame()\n",
    "english_cleaned['avg-score'] = english_corpus['avg-score']\n",
    "for column in ['reference', 'translation']:\n",
    "    english_cleaned[column] = clean(english_corpus[column], lower = True, \n",
    "                                                    remove_char = True,\n",
    "                                                    remove_stop = True,\n",
    "                                                    lemmatize = True,\n",
    "                                                    stemmer = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg-score</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>grab weapon forearm shoulder hit face free elbow</td>\n",
       "      <td>grasp gun forearm shoulder hitting face free e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>new york changed also rediscovery</td>\n",
       "      <td>new york change also reinvention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.500000</td>\n",
       "      <td>thinking summer improve give depth need get hi...</td>\n",
       "      <td>thought long hard course summer might improve ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.500000</td>\n",
       "      <td>find another way cheat somewhere</td>\n",
       "      <td>find another way defraud others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.666667</td>\n",
       "      <td>report replacement president administration he...</td>\n",
       "      <td>news replacement top president office come sur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg-score                                          reference  \\\n",
       "0  60.000000   grab weapon forearm shoulder hit face free elbow   \n",
       "1  44.000000                  new york changed also rediscovery   \n",
       "2  96.500000  thinking summer improve give depth need get hi...   \n",
       "3  90.500000                   find another way cheat somewhere   \n",
       "4  74.666667  report replacement president administration he...   \n",
       "\n",
       "                                         translation  \n",
       "0  grasp gun forearm shoulder hitting face free e...  \n",
       "1                   new york change also reinvention  \n",
       "2  thought long hard course summer might improve ...  \n",
       "3                    find another way defraud others  \n",
       "4  news replacement top president office come sur...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Train, Development and Test sets <a class=\"anchor\" id=\"3.2.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = english_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train-dev-test split\n",
    "train, test = train_test_split(english_cleaned, test_size=0.2, shuffle = True, random_state = 7)\n",
    "test, dev = train_test_split(test, test_size=0.5, shuffle = True, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Metrics <a class=\"anchor\" id=\"4.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU\n",
    "**How to evauate a translation: BLEU**\\\n",
    "One thing you might do is look at each word in the output sentence and assign it a score of 1 if it shows up in any of the reference sentences and 0 if it doesn’t. Then, to normalize that count so that it’s always between 0 and 1, you can divide the number of words that showed up in one of the reference translations by the total number of words in the output sentence. This gives us a measure called unigram precision.\\\n",
    "https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213\n",
    "\n",
    "\\\n",
    "**A Gentle Introduction to Calculating the BLEU Score for Text in Python**\n",
    "https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "\n",
    "\\\n",
    "**NLP Metrics Made Simple: The BLEU Score**\\\n",
    "https://towardsdatascience.com/nlp-metrics-made-simple-the-bleu-score-b06b14fbdbc1\n",
    "\n",
    "\n",
    "\\\n",
    "\"A popular metric is BLEU, which counts the sequences of words in the candidate that also appear in the reference (the BLEU score is very similar to precision).\"\\\n",
    "https://ai.googleblog.com/2020/05/evaluating-natural-language-generation.html#:~:text=BLEURT%20is%20a%20novel,%20machine,ratings%20provided%20by%20the%20user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "## Example\n",
    "reference = [['this', 'is', 'a', 'test'], ['this', 'is' 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative BLEU score\n",
    "def avg_bleu_score(df, ngram = 'unigram'):\n",
    "    bleu_scores = []\n",
    "    for i in df.index:\n",
    "        reference = []\n",
    "        reference.append(df['reference'][i].split(' '))\n",
    "        translation = df['translation'][i].split(' ')\n",
    "        if ngram == 'bigram':\n",
    "            bleu_scores.append(sentence_bleu(reference, translation, weights=(0.5, 0.5, 0, 0)))\n",
    "        elif ngram == '3-gram':\n",
    "            bleu_scores.append(sentence_bleu(reference, translation, weights=(0.33, 0.33, 0.33, 0)))\n",
    "        elif ngram == '4-gram':\n",
    "            bleu_scores.append(sentence_bleu(reference, translation, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "        else:\n",
    "            bleu_scores.append(sentence_bleu(reference, translation))\n",
    "    return pd.Series(bleu_scores).mean(), bleu_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the scores\n",
    "bleu_score_unigram, unigram_scores = avg_bleu_score(train)\n",
    "bleu_score_bigram, bigram_scores = avg_bleu_score(train, ngram = 'bigram')\n",
    "bleu_score_3gram, trigram_scores = avg_bleu_score(train, ngram = '3-gram')\n",
    "bleu_score_4gram, fourgram_scores = avg_bleu_score(train, ngram = '4-gram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score for unigram  : 0.2076622654785226\n",
      "Average BLEU score for bigram  : 0.4090547842910233\n",
      "Average BLEU score for 3-gram  : 0.297260902239954\n",
      "Average BLEU score for 4-gram  : 0.2076622654785226\n"
     ]
    }
   ],
   "source": [
    "grams = ['unigram', 'bigram', '3-gram', '4-gram']\n",
    "bleu_scores = [bleu_score_unigram, bleu_score_bigram, bleu_score_3gram, bleu_score_4gram]\n",
    "for i in range(len(grams)):\n",
    "    print('Average BLEU score for', grams[i] ,' :', bleu_scores[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the correlation with the avg-score\n",
    "bleu_score_relation = pd.concat([train.reset_index(drop=True), pd.Series(unigram_scores)], axis = 1).iloc[:, -2:]\n",
    "pearson_unigram = bleu_score_relation.corr(method='pearson').iloc[1:2,:1].values[0][0]\n",
    "bleu_score_relation = pd.concat([train.reset_index(drop=True), pd.Series(bigram_scores)], axis = 1).iloc[:, -2:]\n",
    "pearson_bigram = bleu_score_relation.corr(method='pearson').iloc[1:2,:1].values[0][0]\n",
    "bleu_score_relation = pd.concat([train.reset_index(drop=True), pd.Series(trigram_scores)], axis = 1).iloc[:, -2:]\n",
    "pearson_3gram = bleu_score_relation.corr(method='pearson').iloc[1:2,:1].values[0][0]\n",
    "bleu_score_relation = pd.concat([train.reset_index(drop=True), pd.Series(fourgram_scores)], axis = 1).iloc[:, -2:]\n",
    "pearson_4gram = bleu_score_relation.corr(method='pearson').iloc[1:2,:1].values[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson relations among Bleu and score unigram  : 0.2556770746721379\n",
      "Pearson relations among Bleu and score bigram  : 0.3120262696218851\n",
      "Pearson relations among Bleu and score 3-gram  : 0.2856859598242893\n",
      "Pearson relations among Bleu and score 4-gram  : 0.2556770746721379\n"
     ]
    }
   ],
   "source": [
    "pearson_grams = [pearson_unigram, pearson_bigram, pearson_3gram, pearson_4gram]\n",
    "for i in range(len(grams)):\n",
    "    print('Pearson relations among Bleu and score', grams[i] ,' :', pearson_grams[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROUGE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Ultimate Performance Metric in NLP**\\\n",
    "https://towardsdatascience.com/the-ultimate-performance-metric-in-nlp-111df6c64460\n",
    "http://www.ccs.neu.edu/home/vip/teach/DMcourse/5_topicmodel_summ/notes_slides/What-is-ROUGE.pdf\n",
    "\n",
    "**How to evauate a translation: Rouge**\n",
    "\n",
    "ROUGE-N measures the number of matching ‘n-grams’ between our model-generated text and a ‘reference’. Once we have decided which N to use — we now decide on whether we’d like to calculate the ROUGE recall, precision, or F1 score.\\\n",
    "ROUGE-L measures the longest common subsequence (LCS) between our model output and reference. All this means is that we count the longest sequence of tokens that is shared between both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rouge\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = \"he began by starting a five person war cabinet and included chamberlain as lord president of the council\"\n",
    "reference = \"he began his premiership by forming a five-man war cabinet which included chamberlain as lord president of the council\"\n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to evauate a translation: Rouge**\\\n",
    "The get_scores method returns three metrics, ROUGE-N using a unigram (ROUGE-1) and a bigram (ROUGE-2) — and ROUGE-L.\n",
    "For each of these, we receive the F1 score f, precision p, and recall r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rouge-1': {'f': 0.7567567517604091, 'p': 0.7777777777777778, 'r': 0.7368421052631579}, 'rouge-2': {'f': 0.514285709289796, 'p': 0.5294117647058824, 'r': 0.5}, 'rouge-l': {'f': 0.7567567517604091, 'p': 0.7777777777777778, 'r': 0.7368421052631579}}]\n"
     ]
    }
   ],
   "source": [
    "scores = rouge.get_scores(model_out, reference)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Real:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "references =df['reference'].to_list()\n",
    "translation =df['translation'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77688\n",
      "77688\n"
     ]
    }
   ],
   "source": [
    "print(len(references))\n",
    "print(len(translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.5976460310969777,\n",
       "  'p': 0.6075188171878395,\n",
       "  'r': 0.5975205263220686},\n",
       " 'rouge-2': {'f': 0.33520325254967454,\n",
       "  'p': 0.340811401059499,\n",
       "  'r': 0.3348847621445332},\n",
       " 'rouge-l': {'f': 0.5499618408308292,\n",
       "  'p': 0.563194001821836,\n",
       "  'r': 0.5445585779541465}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = rouge.get_scores(references, translation, avg=True,ignore_empty=True)\n",
    "scores"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLEURT\n",
    "### Bilingual Evaluation Understudy with Representations from Transformers\n",
    "BLEURT is a novel, machine learning-based automatic metric that can capture non-trivial semantic similarities between sentences. It is trained on a public collection of ratings (the WMT Metrics Shared Task dataset) as well as additional ratings provided by the user.\n",
    "\n",
    "\\\n",
    "The success of BLEURT relies on “warming-up” the model using millions of synthetic sentence pairs before fine-tuning on human ratings. We generated training data by applying random perturbations to sentences from Wikipedia. Instead of collecting human ratings, we use a collection of metrics and models from the literature (including BLEU), which allows the number of training examples to be scaled up at very low cost.\n",
    "\n",
    "\\\n",
    "For example, BLEURT is ~48% more accurate than BLEU on the WMT Metrics Shared Task of 2019. We also demonstrate that pre-training helps BLEURT cope with quality drift.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\\\n",
    "Article:https://ai.googleblog.com/2020/05/evaluating-natural-language-generation.html#:~:text=BLEURT%20is%20a%20novel,%20machine,ratings%20provided%20by%20the%20user \\\n",
    "GitHub: https://github.com/google-research/bleurt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bleurt\n",
    "# from bleurt import checkpoint as checkpoint_lib\n",
    "# from bleurt import encoding\n",
    "# from bleurt import model\n",
    "# from bleurt.lib import experiment_utils\n",
    "# import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_finetuning_pipeline(train_set, dev_set, run_in_lazy_mode=True):\n",
    "#   \"\"\"Runs the full BLEURT fine-tuning pipeline.\"\"\"\n",
    "\n",
    "#   if run_in_lazy_mode:\n",
    "#     tf.disable_eager_execution()\n",
    "\n",
    "#   bleurt_params = checkpoint_lib.get_bleurt_params_from_flags_or_ckpt()\n",
    "\n",
    "#   # Preprocessing and encoding for train and dev set.\n",
    "#   logging.info(\"*** Running pre-processing pipeline for training examples.\")\n",
    "#   if FLAGS.serialized_train_set:\n",
    "#     train_tfrecord = FLAGS.serialized_train_set\n",
    "#   else:\n",
    "#     train_tfrecord = train_set + \".tfrecord\"\n",
    "#   encoding.encode_and_serialize(\n",
    "#       train_set,\n",
    "#       train_tfrecord,\n",
    "#       vocab_file=bleurt_params[\"vocab_file\"],\n",
    "#       do_lower_case=bleurt_params[\"do_lower_case\"],\n",
    "#       sp_model=bleurt_params[\"sp_model\"],\n",
    "#       max_seq_length=bleurt_params[\"max_seq_length\"])\n",
    "\n",
    "#   logging.info(\"*** Running pre-processing pipeline for eval examples.\")\n",
    "#   if FLAGS.serialized_dev_set:\n",
    "#     dev_tfrecord = FLAGS.serialized_dev_set\n",
    "#   else:\n",
    "#     dev_tfrecord = dev_set + \".tfrecord\"\n",
    "#   encoding.encode_and_serialize(\n",
    "#       dev_set,\n",
    "#       dev_tfrecord,\n",
    "#       vocab_file=bleurt_params[\"vocab_file\"],\n",
    "#       do_lower_case=bleurt_params[\"do_lower_case\"],\n",
    "#       sp_model=bleurt_params[\"sp_model\"],\n",
    "#       max_seq_length=bleurt_params[\"max_seq_length\"])\n",
    "\n",
    "#   # Actual fine-tuning work.\n",
    "#   logging.info(\"*** Running fine-tuning.\")\n",
    "#   train_eval_fun = experiment_utils.run_experiment\n",
    "#   model.run_finetuning(train_tfrecord, dev_tfrecord, train_eval_fun)\n",
    "\n",
    "#   # Deletes temp files.\n",
    "#   if not FLAGS.serialized_train_set:\n",
    "#     logging.info(\"Deleting serialized training examples.\")\n",
    "#     tf.io.gfile.remove(train_tfrecord)\n",
    "#   if not FLAGS.serialized_dev_set:\n",
    "#     logging.info(\"Deleting serialized dev examples.\")\n",
    "#     tf.io.gfile.remove(dev_tfrecord)\n",
    "\n",
    "#   # Gets export location.\n",
    "#   glob_pattern = os.path.join(FLAGS.model_dir, \"export\", \"bleurt_best\", \"*\")\n",
    "#   export_dirs = tf.io.gfile.glob(glob_pattern)\n",
    "#   assert export_dirs, \"Model export directory not found.\"\n",
    "#   export_dir = export_dirs[0]\n",
    "\n",
    "#   # Finalizes the BLEURT checkpoint.\n",
    "#   logging.info(\"Exporting BLEURT checkpoint to {}.\".format(export_dir))\n",
    "#   checkpoint_lib.finalize_bleurt_checkpoint(export_dir)\n",
    "\n",
    "#   return export_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_finetuning_pipeline(train, dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "**Sklearn : BOW**\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "**Sklearn : TF-IDF**\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for encoding the text\n",
    "def encoding(train, dev, test, vectorizer):\n",
    "    baseline_encoder = vectorizer()\n",
    "    names = ['train', 'dev', 'test']\n",
    "    for i,df in enumerate([train, dev, test]):\n",
    "        for column in ['reference', 'translation']:\n",
    "            encoded_df = names[i] + '_encoded_' + column\n",
    "            if i == 0:\n",
    "                vars()[encoded_df] = baseline_encoder.fit_transform(df[column]).todense()\n",
    "            else:\n",
    "                vars()[encoded_df] = baseline_encoder.transform(df[column]).todense()           \n",
    "        y_name = 'y_' + names[i].split('_')[0]\n",
    "        vars()[y_name] = np.array(df['avg-score'])\n",
    "    return train_encoded_translation, train_encoded_reference, dev_encoded_reference,\\\n",
    "           dev_encoded_translation, test_encoded_translation, test_encoded_reference\n",
    "\n",
    "# checking the sparsity of the encoded matrix\n",
    "def get_sparsity(sparse_matrix):\n",
    "    ''' Check for sparsity of the dataset'''\n",
    "    matrix_size = sparse_matrix.shape[0]*sparse_matrix.shape[1] # Number of possible interactions in the matrix\n",
    "    num_words = len(sparse_matrix.nonzero()[0]) # Number of words interacted with\n",
    "    sparsity = 100*(1 - (num_words/matrix_size))\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_encoded_translation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-2fe3f68aefc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# encoding(train, dev, test, TfidfVectorizer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-27964bc9abea>\u001b[0m in \u001b[0;36mencoding\u001b[1;34m(train, dev, test, vectorizer)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0my_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'y_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg-score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_encoded_translation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_encoded_reference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_encoded_reference\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m            \u001b[0mdev_encoded_translation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_encoded_translation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_encoded_reference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_encoded_translation' is not defined"
     ]
    }
   ],
   "source": [
    "# encoding(train, dev, test, TfidfVectorizer)\n",
    "encoding(train, dev, test, CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.84900650211618"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sparsity(train_encoded_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_encoder = CountVectorizer()\n",
    "names = ['train', 'dev', 'test']\n",
    "for i,df in enumerate([train, dev, test]):\n",
    "    for column in ['reference', 'translation']:\n",
    "        encoded_df = names[i] + '_encoded_' + column\n",
    "        if i == 0:\n",
    "            vars()[encoded_df] = baseline_encoder.fit_transform(df[column]).todense()\n",
    "        else:\n",
    "            vars()[encoded_df] = baseline_encoder.transform(df[column]).todense()           \n",
    "    y_name = 'y_' + names[i].split('_')[0]\n",
    "    vars()[y_name] = np.array(df['avg-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_encoded_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded = np.hstack((train_encoded_reference, train_encoded_translation))\n",
    "dev_encoded = np.hstack((dev_encoded_reference, dev_encoded_translation))\n",
    "test_encoded = np.hstack((test_encoded_reference, test_encoded_translation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_encoded = pd.DataFrame(train_encoded)\n",
    "# dev_encoded = pd.DataFrame(dev_encoded)\n",
    "# test_encoded = pd.DataFrame(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5954      65.666667\n",
       "34334     85.500000\n",
       "47395    100.000000\n",
       "20160     77.000000\n",
       "18324     79.000000\n",
       "            ...    \n",
       "53459     47.500000\n",
       "10742    100.000000\n",
       "49689     27.000000\n",
       "58564     62.000000\n",
       "61615     40.500000\n",
       "Name: avg-score, Length: 62150, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['avg-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62150,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['avg-score'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score_classes(df):\n",
    "    score_classes = []\n",
    "    for i in df['avg-score']:\n",
    "        if i <= 20:\n",
    "            score_classes.append(1)\n",
    "        elif i <= 40:\n",
    "            score_classes.append(2)\n",
    "        elif i <= 60:\n",
    "            score_classes.append(3)\n",
    "        elif i <= 80:\n",
    "            score_classes.append(4)\n",
    "        else:\n",
    "            score_classes.append(5)\n",
    "    df['score_classes'] = score_classes\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>score_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>i wa hoping to be in it until the end</td>\n",
       "      <td>i had hoped to see it through to the end but t...</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34334</th>\n",
       "      <td>the imam interviewed by kommersant who conduct...</td>\n",
       "      <td>the imam interviewed by kommersant who were co...</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47395</th>\n",
       "      <td>fiji gave master class on the ownership of bal...</td>\n",
       "      <td>fiji gave a masterclass in handling off loadin...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>he did not violate his information duty he said</td>\n",
       "      <td>according to the judgement the organiser had n...</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18324</th>\n",
       "      <td>an investigation ha been opened which is a log...</td>\n",
       "      <td>a criminal investigation ha been opened a logi...</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reference  \\\n",
       "5954               i wa hoping to be in it until the end   \n",
       "34334  the imam interviewed by kommersant who conduct...   \n",
       "47395  fiji gave master class on the ownership of bal...   \n",
       "20160    he did not violate his information duty he said   \n",
       "18324  an investigation ha been opened which is a log...   \n",
       "\n",
       "                                             translation   avg-score  \\\n",
       "5954   i had hoped to see it through to the end but t...   65.666667   \n",
       "34334  the imam interviewed by kommersant who were co...   85.500000   \n",
       "47395  fiji gave a masterclass in handling off loadin...  100.000000   \n",
       "20160  according to the judgement the organiser had n...   77.000000   \n",
       "18324  a criminal investigation ha been opened a logi...   79.000000   \n",
       "\n",
       "       score_classes  \n",
       "5954               4  \n",
       "34334              5  \n",
       "47395              5  \n",
       "20160              4  \n",
       "18324              4  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_score_classes(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>score_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62924</th>\n",
       "      <td>he carefully observed the action of his russia...</td>\n",
       "      <td>he carefully observed every word and action of...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47609</th>\n",
       "      <td>but it in my opinion somewhat tire with the su...</td>\n",
       "      <td>but it is also what i find slightly exhausting...</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77239</th>\n",
       "      <td>there is an economic motive</td>\n",
       "      <td>there is also an economic motive</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61084</th>\n",
       "      <td>it is understood that the first shipment of th...</td>\n",
       "      <td>it is understood that the first carriage of go...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47115</th>\n",
       "      <td>the buyer of primark insulted the woman who sh...</td>\n",
       "      <td>primark shopper outraged at woman who brazenly...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reference  \\\n",
       "62924  he carefully observed the action of his russia...   \n",
       "47609  but it in my opinion somewhat tire with the su...   \n",
       "77239                        there is an economic motive   \n",
       "61084  it is understood that the first shipment of th...   \n",
       "47115  the buyer of primark insulted the woman who sh...   \n",
       "\n",
       "                                             translation  avg-score  \\\n",
       "62924  he carefully observed every word and action of...       11.0   \n",
       "47609  but it is also what i find slightly exhausting...       73.0   \n",
       "77239                   there is also an economic motive       93.0   \n",
       "61084  it is understood that the first carriage of go...       69.0   \n",
       "47115  primark shopper outraged at woman who brazenly...        6.0   \n",
       "\n",
       "       score_classes  \n",
       "62924              1  \n",
       "47609              4  \n",
       "77239              5  \n",
       "61084              4  \n",
       "47115              1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_score_classes(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>score_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36920</th>\n",
       "      <td>a such pita and discovers a female redhead gam...</td>\n",
       "      <td>it is in this state that he is found by the re...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15960</th>\n",
       "      <td>de maizi re is also here to make sense</td>\n",
       "      <td>de maizi re is also trying to strike a concili...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51283</th>\n",
       "      <td>bodini said he hoped that the matter could be ...</td>\n",
       "      <td>bordini said he waited for month for the situa...</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49847</th>\n",
       "      <td>bile spent the last three year dominated by it...</td>\n",
       "      <td>bile ha spent the last three year dominating h...</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73972</th>\n",
       "      <td>the moscow city tourist police unit commander ...</td>\n",
       "      <td>lei sakov the brigade captain of moscow city p...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reference  \\\n",
       "36920  a such pita and discovers a female redhead gam...   \n",
       "15960             de maizi re is also here to make sense   \n",
       "51283  bodini said he hoped that the matter could be ...   \n",
       "49847  bile spent the last three year dominated by it...   \n",
       "73972  the moscow city tourist police unit commander ...   \n",
       "\n",
       "                                             translation  avg-score  \\\n",
       "36920  it is in this state that he is found by the re...       40.0   \n",
       "15960  de maizi re is also trying to strike a concili...       19.0   \n",
       "51283  bordini said he waited for month for the situa...       97.0   \n",
       "49847  bile ha spent the last three year dominating h...       98.0   \n",
       "73972  lei sakov the brigade captain of moscow city p...       74.0   \n",
       "\n",
       "       score_classes  \n",
       "36920              2  \n",
       "15960              1  \n",
       "51283              5  \n",
       "49847              5  \n",
       "73972              4  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_score_classes(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model <a class=\"anchor\" id=\"5.\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional, GRU\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>score_classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>i wa hoping to be in it until the end</td>\n",
       "      <td>i had hoped to see it through to the end but t...</td>\n",
       "      <td>65.666667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34334</th>\n",
       "      <td>the imam interviewed by kommersant who conduct...</td>\n",
       "      <td>the imam interviewed by kommersant who were co...</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47395</th>\n",
       "      <td>fiji gave master class on the ownership of bal...</td>\n",
       "      <td>fiji gave a masterclass in handling off loadin...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20160</th>\n",
       "      <td>he did not violate his information duty he said</td>\n",
       "      <td>according to the judgement the organiser had n...</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18324</th>\n",
       "      <td>an investigation ha been opened which is a log...</td>\n",
       "      <td>a criminal investigation ha been opened a logi...</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reference  \\\n",
       "5954               i wa hoping to be in it until the end   \n",
       "34334  the imam interviewed by kommersant who conduct...   \n",
       "47395  fiji gave master class on the ownership of bal...   \n",
       "20160    he did not violate his information duty he said   \n",
       "18324  an investigation ha been opened which is a log...   \n",
       "\n",
       "                                             translation   avg-score  \\\n",
       "5954   i had hoped to see it through to the end but t...   65.666667   \n",
       "34334  the imam interviewed by kommersant who were co...   85.500000   \n",
       "47395  fiji gave a masterclass in handling off loadin...  100.000000   \n",
       "20160  according to the judgement the organiser had n...   77.000000   \n",
       "18324  a criminal investigation ha been opened a logi...   79.000000   \n",
       "\n",
       "       score_classes  \n",
       "5954               4  \n",
       "34334              5  \n",
       "47395              5  \n",
       "20160              4  \n",
       "18324              4  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62150, 3)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = train[['reference', 'translation', 'score_classes']]\n",
    "train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-443ffaa82ccb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# output embedding dimension of size 64.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_encoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'avg-score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\embeddings.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dim, output_dim, embeddings_initializer, embeddings_regularizer, activity_regularizer, embeddings_constraint, mask_zero, input_length, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_shape'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0minput_dim\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0moutput_dim\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m       raise ValueError('Both `input_dim` and `output_dim` should be positive, '\n\u001b[0;32m    108\u001b[0m                        'found input_dim {} and output_dim {}'.format(\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "\n",
    "model.add(layers.Embedding(input_dim = train_encoded.shape, output_dim = train['avg-score'].shape[0]))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(32, (3,3), input_shape = (62150,3) , activation = 'relu'))\n",
    "# # creating a Pooling layer: each window (pool) has size (2,2)\n",
    "# model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "# model.add(layers.Dense(5, activation = 'linear'))\n",
    "\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the created model\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_base_build(input_shape):\n",
    "    #build the lstm model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, return_sequences=True,kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01), input_shape = input_shape))\n",
    "    model.add(LSTM(100, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    #compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "def accuracy_forecast(target_val ,prediction_val):   \n",
    "    bi_targ = np.sign(target_val.rolling(window=2).apply(lambda x: x.iloc[1] - x.iloc[0]))[1:].values\n",
    "    bi_pred = np.sign(prediction_val.rolling(window=2).apply(lambda x: x.iloc[1] - x.iloc[0]))[1:].values\n",
    "    return accuracy_score(bi_targ,bi_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62150"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoded.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62924    11.0\n",
       "47609    73.0\n",
       "77239    93.0\n",
       "61084    69.0\n",
       "47115     6.0\n",
       "         ... \n",
       "44784     7.0\n",
       "17179    49.0\n",
       "76833    93.0\n",
       "15871    38.0\n",
       "68247    48.0\n",
       "Name: avg-score, Length: 7769, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev['avg-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Bidirectional, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM1 = model_base_build(input_shape= (train_encoded.shape[0], train_encoded.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:754 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:219 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 36658)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-1660b21b5163>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history1 = LSTM1.fit(train_encoded, train['avg-score'], \n\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                      validation_data=(dev_encoded, dev['avg-score']))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    869\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 725\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    726\u001b[0m             *args, **kwds))\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2968\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2969\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2970\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:754 train_step\n        y_pred = self(x, training=True)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:219 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 36658)\n"
     ]
    }
   ],
   "source": [
    "history1 = LSTM1.fit(train_encoded, train['avg-score'], \n",
    "                     batch_size=32, \n",
    "                     epochs=5,\n",
    "                     validation_data=(dev_encoded, dev['avg-score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
