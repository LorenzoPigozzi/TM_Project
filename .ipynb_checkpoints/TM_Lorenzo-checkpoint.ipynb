{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Project\n",
    "\n",
    "### NOVA IMS MT Metrics Shared Task\n",
    "\n",
    "**Group members:**\n",
    "- Lorenzo Pigozzi\t--- m20200745\n",
    "- Davide Farinati\n",
    "- Antonio\n",
    "- Luis Reis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**\n",
    "\n",
    "The goal of this project is to develop a metric that predicts the quality of a translation using the reference. \n",
    "\n",
    "\\\n",
    "**Evaluation**\\\n",
    "Your metric should correlate well with the existing quality assessments that you have in the above corpus.\n",
    "The one that we have so far are just the training sets, we will have a test set without the z-score, average score and annotators.\n",
    "Produce our own metric that will be compared with the existing ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0.1\"></a>\n",
    "# **Table of Contents**\n",
    "\n",
    "1.\t[Importing libraries and corpora](#1)   \n",
    "2.\t[Brief Exploratory data analysis (EDA)](#2)       \n",
    "3.\t[Baseline](#3)     \n",
    " 3.1. [Pre-processing](#3.1.)\\\n",
    " 3.2. [Feature Extraction](#3.2.)\\\n",
    " 3.3. [Model](#3.3.)\\\n",
    " 3.4. [Evaluation](#3.4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\\\n",
    "Sklearn:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries and corpora <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# word's preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing the corpora\n",
    "cs_en = pd.read_csv('corpus\\cs-en\\scores.csv')\n",
    "de_en = pd.read_csv('corpus\\de-en\\scores.csv')\n",
    "ru_en = pd.read_csv('corpus\\scores_ru-en.csv')\n",
    "zh_en = pd.read_csv('corpus\\zh-en\\scores.csv')\n",
    "en_fi = pd.read_csv('corpus\\en-fi\\scores.csv')\n",
    "en_zh = pd.read_csv('corpus\\en-zh\\scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Brief Exploratory Data Analysis <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can turn yourself into a pineapple, a dog ...</td>\n",
       "      <td>Voit muuttaa itsesi ananasta, koirasta tai Roy...</td>\n",
       "      <td>Voit muuttaa itsesi ananakseksi, koiraksi tai ...</td>\n",
       "      <td>-0.286195</td>\n",
       "      <td>34.20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Also shot were three men: two 29-year-olds and...</td>\n",
       "      <td>Myös ammuttiin kolme miestä: kaksi 29-vuotiait...</td>\n",
       "      <td>Myös kolmea miestä ammuttiin: kahta 29-vuotias...</td>\n",
       "      <td>0.547076</td>\n",
       "      <td>58.40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The information is stored at the cash register...</td>\n",
       "      <td>Tiedot tallennetaan kassakoneisiin joka tapauk...</td>\n",
       "      <td>Tiedot kuitenkin tallentuvat kassoilla joka ta...</td>\n",
       "      <td>1.122476</td>\n",
       "      <td>74.60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xinhua says that there were traces of hydrochl...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin näytteestä oli sunn...</td>\n",
       "      <td>Xinhua kertoo, että Xinyin sunnuntaina antamas...</td>\n",
       "      <td>0.383095</td>\n",
       "      <td>53.60</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MacDonald, who was brought on board CBC's comm...</td>\n",
       "      <td>Voitaisiin kuulla CBD: n kommenttitiimin toimi...</td>\n",
       "      <td>MacDonaldin, joka tuli CBC:n selostajatiimiin ...</td>\n",
       "      <td>-0.493065</td>\n",
       "      <td>32.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  You can turn yourself into a pineapple, a dog ...   \n",
       "1  Also shot were three men: two 29-year-olds and...   \n",
       "2  The information is stored at the cash register...   \n",
       "3  Xinhua says that there were traces of hydrochl...   \n",
       "4  MacDonald, who was brought on board CBC's comm...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  Voit muuttaa itsesi ananasta, koirasta tai Roy...   \n",
       "1  Myös ammuttiin kolme miestä: kaksi 29-vuotiait...   \n",
       "2  Tiedot tallennetaan kassakoneisiin joka tapauk...   \n",
       "3  Xinhua kertoo, että Xinyin näytteestä oli sunn...   \n",
       "4  Voitaisiin kuulla CBD: n kommenttitiimin toimi...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  Voit muuttaa itsesi ananakseksi, koiraksi tai ... -0.286195      34.20   \n",
       "1  Myös kolmea miestä ammuttiin: kahta 29-vuotias...  0.547076      58.40   \n",
       "2  Tiedot kuitenkin tallentuvat kassoilla joka ta...  1.122476      74.60   \n",
       "3  Xinhua kertoo, että Xinyin sunnuntaina antamas...  0.383095      53.60   \n",
       "4  MacDonaldin, joka tuli CBC:n selostajatiimiin ... -0.493065      32.25   \n",
       "\n",
       "   annotators  \n",
       "0           5  \n",
       "1           5  \n",
       "2           5  \n",
       "3           5  \n",
       "4           4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_fi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\\\n",
    "All the the Dataframes imported have 6 columns:\n",
    "- Sources: the original text in the original language\n",
    "- Reference: The correct translation\n",
    "- Translation: the translation that we will evaluate\n",
    "- Z-score: score of the translation normalized\n",
    "- Avg-score: score of the translation from 0 to 100\n",
    "- Annotators: number of annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of translations :  94657\n"
     ]
    }
   ],
   "source": [
    "print('Total number of translations : ',len(cs_en) + len(de_en) + len(ru_en) + len(zh_en) + len(en_fi) + len(en_zh) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea**\\\n",
    "Splitting the problem in 3:\n",
    "- estimate the translations from other languages to English\n",
    "- estimate the translations from English to Finnish\n",
    "- estimate the translations from English to Chinese\n",
    "\n",
    "\\\n",
    "Reason:\\\n",
    "Proably going forward we will need to have different preprocessing for English and for the other 2 languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Pre-processing <a class=\"anchor\" id=\"3.1.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>z-score</th>\n",
       "      <th>avg-score</th>\n",
       "      <th>annotators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uchopíte pak zbraň mezi své předloktí a rameno...</td>\n",
       "      <td>You will then grab the weapon between your for...</td>\n",
       "      <td>You then grasp the gun between your forearm an...</td>\n",
       "      <td>-0.675383</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ale je-li New York změna, pak je to také znovu...</td>\n",
       "      <td>But if New York is changed, then it's also a r...</td>\n",
       "      <td>But if New York is change, it is also reinvent...</td>\n",
       "      <td>-0.829403</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dlouho a intenzivně jsem během léta přemýšlel,...</td>\n",
       "      <td>I have been thinking over and over again over ...</td>\n",
       "      <td>I have thought long and hard over the course o...</td>\n",
       "      <td>0.803185</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Najdou si jiný způsob, jak někde podvádět.</td>\n",
       "      <td>They find another way to cheat somewhere.</td>\n",
       "      <td>They will find another way how to defraud others.</td>\n",
       "      <td>0.563149</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zpráva o výměně v čele prezidentovy administra...</td>\n",
       "      <td>The report on the replacement of the president...</td>\n",
       "      <td>The news of the replacement at the top of the ...</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>74.666667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Uchopíte pak zbraň mezi své předloktí a rameno...   \n",
       "1  Ale je-li New York změna, pak je to také znovu...   \n",
       "2  Dlouho a intenzivně jsem během léta přemýšlel,...   \n",
       "3         Najdou si jiný způsob, jak někde podvádět.   \n",
       "4  Zpráva o výměně v čele prezidentovy administra...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  You will then grab the weapon between your for...   \n",
       "1  But if New York is changed, then it's also a r...   \n",
       "2  I have been thinking over and over again over ...   \n",
       "3          They find another way to cheat somewhere.   \n",
       "4  The report on the replacement of the president...   \n",
       "\n",
       "                                         translation   z-score  avg-score  \\\n",
       "0  You then grasp the gun between your forearm an... -0.675383  60.000000   \n",
       "1  But if New York is change, it is also reinvent... -0.829403  44.000000   \n",
       "2  I have thought long and hard over the course o...  0.803185  96.500000   \n",
       "3  They will find another way how to defraud others.  0.563149  90.500000   \n",
       "4  The news of the replacement at the top of the ...  0.021549  74.666667   \n",
       "\n",
       "   annotators  \n",
       "0           3  \n",
       "1           2  \n",
       "2           2  \n",
       "3           2  \n",
       "4           3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the necessary variables for the baseline\n",
    "cs_en = cs_en[['reference','translation','avg-score']]\n",
    "de_en = de_en[['reference','translation','avg-score']]\n",
    "ru_en = ru_en[['reference','translation','avg-score']]\n",
    "zh_en = zh_en[['reference','translation','avg-score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>avg-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You will then grab the weapon between your for...</td>\n",
       "      <td>You then grasp the gun between your forearm an...</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But if New York is changed, then it's also a r...</td>\n",
       "      <td>But if New York is change, it is also reinvent...</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been thinking over and over again over ...</td>\n",
       "      <td>I have thought long and hard over the course o...</td>\n",
       "      <td>96.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They find another way to cheat somewhere.</td>\n",
       "      <td>They will find another way how to defraud others.</td>\n",
       "      <td>90.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The report on the replacement of the president...</td>\n",
       "      <td>The news of the replacement at the top of the ...</td>\n",
       "      <td>74.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  You will then grab the weapon between your for...   \n",
       "1  But if New York is changed, then it's also a r...   \n",
       "2  I have been thinking over and over again over ...   \n",
       "3          They find another way to cheat somewhere.   \n",
       "4  The report on the replacement of the president...   \n",
       "\n",
       "                                         translation  avg-score  \n",
       "0  You then grasp the gun between your forearm an...  60.000000  \n",
       "1  But if New York is change, it is also reinvent...  44.000000  \n",
       "2  I have thought long and hard over the course o...  96.500000  \n",
       "3  They will find another way how to defraud others.  90.500000  \n",
       "4  The news of the replacement at the top of the ...  74.666667  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the 4 datasets with English translations\n",
    "df = pd.concat([cs_en, de_en, ru_en, zh_en], axis = 0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a few options for preprocessing\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the text\n",
    "def clean(text_list, lemmatize=False):\n",
    "    \"\"\"\n",
    "    Function that a receives a list of strings and preprocesses it.\n",
    "    \n",
    "    :param text_list: List of strings.\n",
    "    :param lemmatize: Tag to apply lemmatization if True.\n",
    "    :param stemmer: Tag to apply the stemmer if True.\n",
    "    \"\"\"\n",
    "    updates = []\n",
    "    for j in tqdm(range(len(text_list))):\n",
    "        \n",
    "        text = text_list[j]\n",
    "        \n",
    "        #LOWERCASE TEXT\n",
    "        text = text.lower()\n",
    "        \n",
    "        #REMOVE NUMERICAL DATA AND PUNCTUATION\n",
    "        text = re.sub(\"[^a-z]\", ' ', text)\n",
    "        \n",
    "        #REMOVE TAGS\n",
    "        text = BeautifulSoup(text).get_text()\n",
    "        \n",
    "        if lemmatize:\n",
    "            text = \" \".join(lemma.lemmatize(word) for word in text.split())\n",
    "        \n",
    "        updates.append(text)\n",
    "        \n",
    "    return updates\n",
    "\n",
    "# function to update the dataframe with the cleaned text\n",
    "def update_df(dataframe, list_updated, variable):\n",
    "    dataframe.update(pd.DataFrame({variable: list_updated}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6ecb4a442cb3>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for j in tqdm(range(len(text_list))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed033099218a4e2c851180c9eb56a1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=77688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cleaning the references\n",
    "updates_reference = clean(df[\"reference\"], lemmatize = True)\n",
    "update_df(df, updates_reference, \"reference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6ecb4a442cb3>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for j in tqdm(range(len(text_list))):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedde8d44023432193f189818ba1ab6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=77688.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>avg-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you will then grab the weapon between your for...</td>\n",
       "      <td>you then grasp the gun between your forearm an...</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>but if new york is changed then it s also a re...</td>\n",
       "      <td>but if new york is change it is also reinvention</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i have been thinking over and over again over ...</td>\n",
       "      <td>i have thought long and hard over the course o...</td>\n",
       "      <td>96.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>they find another way to cheat somewhere</td>\n",
       "      <td>they will find another way how to defraud others</td>\n",
       "      <td>90.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the report on the replacement of the president...</td>\n",
       "      <td>the news of the replacement at the top of the ...</td>\n",
       "      <td>74.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  you will then grab the weapon between your for...   \n",
       "1  but if new york is changed then it s also a re...   \n",
       "2  i have been thinking over and over again over ...   \n",
       "3           they find another way to cheat somewhere   \n",
       "4  the report on the replacement of the president...   \n",
       "\n",
       "                                         translation  avg-score  \n",
       "0  you then grasp the gun between your forearm an...  60.000000  \n",
       "1   but if new york is change it is also reinvention  44.000000  \n",
       "2  i have thought long and hard over the course o...  96.500000  \n",
       "3   they will find another way how to defraud others  90.500000  \n",
       "4  the news of the replacement at the top of the ...  74.666667  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning the translations\n",
    "updates_translation = clean(df[\"translation\"], lemmatize = True)\n",
    "update_df(df, updates_translation, \"translation\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Train, Development and Test sets <a class=\"anchor\" id=\"3.2.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train-dev-test split\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "test, dev = train_test_split(test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating Bag-of-Words\n",
    "# cv = CountVectorizer(max_df=0.9, binary=True)\n",
    "# # fitting and transforming based on the references\n",
    "# references = cv.fit_transform(train[['reference', 'translation']])\n",
    "# # only transforming the translations\n",
    "# translations = cv.transform(dev[['reference', 'translation']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_encoder = CountVectorizer()\n",
    "names = ['train', 'dev', 'test']\n",
    "for i,df in enumerate([train, dev, test]):\n",
    "    for column in ['reference', 'translation']:\n",
    "        encoded_df = names[i] + '_encoded_' + column\n",
    "        if i == 0:\n",
    "            vars()[encoded_df] = baseline_encoder.fit_transform(df[column]).todense()\n",
    "        else:\n",
    "            vars()[encoded_df] = baseline_encoder.transform(df[column]).todense()\n",
    "            \n",
    "    y_name = 'y_' + names[i].split('_')[0]\n",
    "    vars()[y_name] = np.array(df['avg-score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_encoded_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLEU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to evauate a translation: BLEU**\\\n",
    "One thing you might do is look at each word in the output sentence and assign it a score of 1 if it shows up in any of the reference sentences and 0 if it doesn’t. Then, to normalize that count so that it’s always between 0 and 1, you can divide the number of words that showed up in one of the reference translations by the total number of words in the output sentence. This gives us a measure called unigram precision.\\\n",
    "https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213\n",
    "\n",
    "\\\n",
    "**A Gentle Introduction to Calculating the BLEU Score for Text in Python**\n",
    "https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
    "\n",
    "\\\n",
    "**NLP Metrics Made Simple: The BLEU Score**\\\n",
    "https://towardsdatascience.com/nlp-metrics-made-simple-the-bleu-score-b06b14fbdbc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "## Example\n",
    "reference = [['this', 'is', 'a', 'test'], ['this', 'is' 'test']]\n",
    "candidate = ['this', 'is', 'a', 'test']\n",
    "score = sentence_bleu(reference, candidate)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative BLEU score\n",
    "def avg_bleu_score(df, ngram = 'unigram'):\n",
    "    bleu_scores = []\n",
    "    for i in df.index:\n",
    "        reference = []\n",
    "        reference.append(df['reference'][i].split(' '))\n",
    "        translation = df['translation'][i].split(' ')\n",
    "        if ngram == 'bigram':\n",
    "            bleu_scores.append(sentence_bleu(reference, translation, weights=(0.5, 0.5, 0, 0)))\n",
    "        elif ngram == '3-gram':\n",
    "            bleu_scores.append(sentence_bleu(reference, translation, weights=(0.33, 0.33, 0.33, 0)))\n",
    "        elif ngram == '4-gram':\n",
    "            bleu_scores.append(sentence_bleu(reference, translation, weights=(0.25, 0.25, 0.25, 0.25)))\n",
    "        else:\n",
    "            bleu_scores.append(sentence_bleu(reference, translation))\n",
    "    return pd.Series(bleu_scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\lorep\\anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20756861430586115"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bleu_score(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40865181478044393"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bleu_score(train, ngram='bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.296975411534373"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bleu_score(train, ngram='3-gram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20756861430586115"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bleu_score(train, ngram='4-gram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checking the correlation with the avg-score\n",
    "# bleu_score_relation = pd.concat([train.reset_index(drop=True), pd.Series(bleu_scores)], axis = 1).iloc[:, -2:]\n",
    "# bleu_score_relation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bleu_score_relation.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Model <a class=\"anchor\" id=\"3.3.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Evaluation <a class=\"anchor\" id=\"3.4.\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
